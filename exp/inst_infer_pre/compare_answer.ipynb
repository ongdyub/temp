{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "inst_vocab_path = '/workspace/data/vocabs/inst.json'\n",
    "chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "with open(inst_vocab_path, 'r') as file:\n",
    "    inst_vocab = json.load(file)\n",
    "    \n",
    "    \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import Transformer\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from transformers import ASTConfig, ASTModel, GPT2Config, GPT2Model, AutoModelForCausalLM, GPT2LMHeadModel, BartConfig\n",
    "\n",
    "# class GPT2Model(nn.Module):\n",
    "#     def __init__(self, vocab_size=140, n_embd=768, n_layer=12, n_head=12):\n",
    "#         super(GPT2Model, self).__init__()\n",
    "#         self.configuration = GPT2Config(vocab_size=vocab_size, n_embd=n_embd, n_layer=n_layer, n_head=n_head, bos_token_id=2, eos_token_id=1)\n",
    "#         self.model = GPT2LMHeadModel(self.configuration)\n",
    "        \n",
    "#     def get_embed(self, idx):\n",
    "#         embedding_layer = self.model.transformer.wte\n",
    "#         token_embedding = embedding_layer(torch.tensor([idx]))\n",
    "#         return token_embedding\n",
    "    \n",
    "#     def extract_vocab_embeddings(self):\n",
    "#         # Extract all the embeddings for the entire vocabulary\n",
    "#         embedding_layer = self.model.transformer.wte\n",
    "#         vocab_embeddings = embedding_layer.weight.detach().clone()\n",
    "#         return vocab_embeddings\n",
    "\n",
    "#     def forward(self, input_ids, labels=None, return_hidden_states=False):\n",
    "#         attention_mask = self.make_mask(input_ids)\n",
    "#         # Forward pass through the transformer to get hidden states\n",
    "#         transformer_outputs = self.model.transformer(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\n",
    "#         # Extract hidden states before the projection\n",
    "#         hidden_states = transformer_outputs.last_hidden_state\n",
    "        \n",
    "#         if return_hidden_states:\n",
    "#             return hidden_states\n",
    "\n",
    "#         # Project the hidden states to vocabulary size\n",
    "#         logits = self.model.lm_head(hidden_states)\n",
    "\n",
    "#         if labels is not None:\n",
    "#             loss_fct = nn.CrossEntropyLoss()\n",
    "#             loss = loss_fct(logits.view(-1, self.configuration.vocab_size), labels.view(-1))\n",
    "#             return loss, logits\n",
    "#         return logits\n",
    "\n",
    "#     def make_mask(self, input_ids):\n",
    "#         attention_mask = (input_ids != 0).long()\n",
    "#         return attention_mask\n",
    "    \n",
    "#     def infer(self, input_ids, length=2048):\n",
    "#         if len(input_ids.shape) == 1:\n",
    "#             input_ids = input_ids.unsqueeze(0)\n",
    "#         if len(input_ids.shape) > 2:\n",
    "#             raise Exception\n",
    "        \n",
    "#         if length > 2048:\n",
    "#             print(\"Max Length is 2048. Change Length Auto to 2048\")\n",
    "#             length = 2048\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             for step in range(length):\n",
    "#                 logits = self.forward(input_ids)\n",
    "#                 output = torch.argmax(logits, dim=2)\n",
    "\n",
    "#                 predict = output[:,-1].unsqueeze(1)\n",
    "#                 output_ids = torch.cat((input_ids, predict), dim=-1)\n",
    "\n",
    "#                 input_ids = output_ids\n",
    "                \n",
    "#                 if output_ids.shape[1] > 2048:\n",
    "#                     break\n",
    "\n",
    "#         return output_ids\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]  # Broadcasting positional encodings\n",
    "        return x  # Shape: (batch_size, seq_len, d_model)\n",
    "    \n",
    "class NormEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(NormEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        x = x + self.pe[:, :x.size(1), :]  # Broadcasting positional encodings\n",
    "        return x  # Shape: (batch_size, seq_len, d_model)\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        assert d_model % num_heads == 0  # d_model must be divisible by num_heads\n",
    "        self.d_k = d_model // num_heads\n",
    "        self.num_heads = num_heads\n",
    "        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])  # Q, K, V, and output projections\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        # query, key, value shape: (batch_size, seq_len, d_model)\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Linear projections\n",
    "        query, key, value = [l(x).view(batch_size, -1, self.num_heads, self.d_k).transpose(1, 2)\n",
    "                             for l, x in zip(self.linears, (query, key, value))]\n",
    "        # After projection and reshaping: (batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        if mask is not None:\n",
    "            scores = scores.masked_fill(mask == 0, -1e9)\n",
    "        attn = F.softmax(scores, dim=-1)\n",
    "        attn_output = torch.matmul(attn, value)\n",
    "        # attn_output shape: (batch_size, num_heads, seq_len, d_k)\n",
    "\n",
    "        # Concatenate heads and apply final linear projection\n",
    "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, -1, self.num_heads * self.d_k)\n",
    "        return self.linears[-1](attn_output)  # Shape: (batch_size, seq_len, d_model)\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear2 = nn.Linear(d_ff, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        return self.linear2(F.relu(self.linear1(x)))  # Shape: (batch_size, seq_len, d_model)\n",
    "    \n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        attn_output = self.self_attn(x, x, x, mask)  # Self-attention\n",
    "        x = x + self.dropout(attn_output)  # Add & Norm\n",
    "        x = self.layernorm1(x)\n",
    "\n",
    "        ff_output = self.feed_forward(x)  # Feed forward\n",
    "        x = x + self.dropout(ff_output)  # Add & Norm\n",
    "        return self.layernorm2(x)  # Shape: (batch_size, seq_len, d_model)\n",
    "    \n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = FeedForward(d_model, d_ff)\n",
    "        self.layernorm1 = nn.LayerNorm(d_model)\n",
    "        self.layernorm2 = nn.LayerNorm(d_model)\n",
    "        self.layernorm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, memory, src_mask=None, tgt_mask=None):\n",
    "        # x shape: (batch_size, tgt_len, d_model)\n",
    "        # memory shape: (batch_size, src_len, d_model)\n",
    "\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)  # Self-attention\n",
    "        x = x + self.dropout(attn_output)  # Add & Norm\n",
    "        x = self.layernorm1(x)\n",
    "\n",
    "        attn_output = self.cross_attn(x, memory, memory, src_mask)  # Cross-attention\n",
    "        x = x + self.dropout(attn_output)  # Add & Norm\n",
    "        x = self.layernorm2(x)\n",
    "\n",
    "        ff_output = self.feed_forward(x)  # Feed forward\n",
    "        x = x + self.dropout(ff_output)  # Add & Norm\n",
    "        return self.layernorm3(x)  # Shape: (batch_size, tgt_len, d_model)\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, max_len, dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        x = self.embedding(src)  # Embedding\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x  # Shape: (batch_size, src_len, d_model)\n",
    "    \n",
    "class C2IEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, max_len, dropout=0.1, mode='none'):\n",
    "        super(C2IEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.num_classes = 133\n",
    "        self.fc1 = nn.Linear(d_model, d_model // 2)\n",
    "        self.fc2 = nn.Linear(d_model // 2, 133)\n",
    "        if mode == 'len':\n",
    "            self.len_embed = nn.Embedding(770, d_model)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        \n",
    "        src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        \n",
    "        x = self.embedding(src)  # Embedding\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return x  # Shape: (batch_size, src_len, d_model)\n",
    "    \n",
    "    def generate_src_mask(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, src_len)\n",
    "    \n",
    "    def proj_inst(self, x, length=None):\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        # Use the embedding corresponding to the BOS token (assumed to be the first token)\n",
    "        bos_embedding = x[:, 0, :]  # Shape: (batch_size, d_model)\n",
    "        \n",
    "        if length == None:\n",
    "            # First fully connected layer\n",
    "            x = self.fc1(bos_embedding)  # Shape: (batch_size, d_model // 2)\n",
    "            x = torch.relu(x)  # Apply ReLU activation\n",
    "            \n",
    "            # Second fully connected layer\n",
    "            out = self.fc2(x)  # Shape: (batch_size, num_classes)\n",
    "        else:\n",
    "            # First fully connected layer\n",
    "            len_embed = self.len_embed(length)\n",
    "            len_embed = len_embed.squeeze(1)\n",
    "            len_embed = len_embed/4\n",
    "\n",
    "            bos_embedding = bos_embedding + len_embed\n",
    "            x = self.fc1(bos_embedding)  # Shape: (batch_size, d_model // 2)\n",
    "            x = torch.relu(x)  # Apply ReLU activation\n",
    "            \n",
    "            # Second fully connected layer\n",
    "            out = self.fc2(x)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def avg_inst(self, x, length=None):\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        # Use the embedding corresponding to the BOS token (assumed to be the first token)\n",
    "        bos_embedding = torch.mean(x, dim=1)  # Shape: (batch_size, d_model)\n",
    "        \n",
    "        if length == None:\n",
    "            # First fully connected layer\n",
    "            x = self.fc1(bos_embedding)  # Shape: (batch_size, d_model // 2)\n",
    "            x = torch.relu(x)  # Apply ReLU activation\n",
    "            \n",
    "            # Second fully connected layer\n",
    "            out = self.fc2(x)  # Shape: (batch_size, num_classes)\n",
    "        else:\n",
    "            # First fully connected layer\n",
    "            len_embed = self.len_embed(length)\n",
    "            len_embed = len_embed.squeeze(1)\n",
    "            len_embed = len_embed/4\n",
    "            bos_embedding = bos_embedding + len_embed\n",
    "            x = self.fc1(bos_embedding)  # Shape: (batch_size, d_model // 2)\n",
    "            x = torch.relu(x)  # Apply ReLU activation\n",
    "            \n",
    "            # Second fully connected layer\n",
    "            out = self.fc2(x)  # Shape: (batch_size, num_classes)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, max_len, dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, src_mask=None, tgt_mask=None):\n",
    "        # tgt shape: (batch_size, tgt_len)\n",
    "        x = self.embedding(tgt)  # Embedding\n",
    "        # x shape: (batch_size, tgt_len, d_model)\n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return x  # Shape: (batch_size, tgt_len, d_model)\n",
    "    \n",
    "class InstDecoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, max_len, dropout=0.1):\n",
    "        super(InstDecoder, self).__init__()\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, tgt, memory, src_mask=None, tgt_mask=None):\n",
    "        \n",
    "        x = self.positional_encoding(tgt)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return x  # Shape: (batch_size, tgt_len, d_model)\n",
    "    \n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, num_heads=8, d_ff=2048, num_layers=6, max_len=5000, dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(d_model, num_heads, d_ff, num_layers, src_vocab_size, max_len, dropout)\n",
    "        self.decoder = Decoder(d_model, num_heads, d_ff, num_layers, tgt_vocab_size, max_len, dropout)\n",
    "        self.out = nn.Linear(d_model, tgt_vocab_size)\n",
    "        \n",
    "    def generate_src_mask(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, src_len)\n",
    "\n",
    "    def generate_tgt_mask(self, tgt):\n",
    "        # tgt shape: (batch_size, tgt_len)\n",
    "        tgt_len = tgt.size(1)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(2)  # Padding mask: (batch_size, 1, 1, tgt_len)\n",
    "        nopeak_mask = torch.tril(torch.ones((tgt_len, tgt_len), device=tgt.device)).bool()  # Look-ahead mask\n",
    "        tgt_mask = tgt_mask & nopeak_mask.unsqueeze(0)  # Combined mask: (batch_size, 1, tgt_len, tgt_len)\n",
    "        return tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt, src_mask=None, tgt_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        # tgt shape: (batch_size, tgt_len)\n",
    "        \n",
    "        src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        tgt_mask = self.generate_tgt_mask(tgt)  # Generate target mask\n",
    "\n",
    "        memory = self.encoder(src, src_mask)  # Encoder output\n",
    "        # memory shape: (batch_size, src_len, d_model)\n",
    "\n",
    "        output = self.decoder(tgt, memory, src_mask, tgt_mask)  # Decoder output\n",
    "        # output shape: (batch_size, tgt_len, d_model)\n",
    "\n",
    "        return self.out(output)  # Final output projection, shape: (batch_size, tgt_len, tgt_vocab_size)\n",
    "    \n",
    "    def infer(self, src, x, length=766):\n",
    "        with torch.no_grad():\n",
    "            for step in range(length):\n",
    "                output = self.forward(src, x)\n",
    "                output = torch.argmax(output, dim=2)\n",
    "\n",
    "                predict = output[:,-1].unsqueeze(1)\n",
    "                output_ids = torch.cat((x, predict), dim=-1)\n",
    "\n",
    "                x = output_ids\n",
    "                \n",
    "                # if torch.all(predict.eq(0)):\n",
    "                #     break\n",
    "                \n",
    "                if output_ids.shape[1] > 2048:\n",
    "                    break\n",
    "\n",
    "        return output_ids\n",
    "        \n",
    "    \n",
    "    \n",
    "class InstEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, inst_size, max_len, dropout=0.1):\n",
    "        super(InstEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.inst_proj = nn.Linear(d_model, inst_size)\n",
    "        \n",
    "    def generate_src_mask(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, src_len)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        x = self.embedding(src)  # Embedding\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        \n",
    "        x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        x = self.inst_proj(x)\n",
    "        return x  # Shape: (batch_size, src_len, inst_size)\n",
    "    \n",
    "class InstNoPEEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, inst_size, max_len, dropout=0.1):\n",
    "        super(InstNoPEEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.inst_proj = nn.Linear(d_model, inst_size)\n",
    "        \n",
    "    def generate_src_mask(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, src_len)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        x = self.embedding(src)  # Embedding\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        \n",
    "        # x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        x = self.inst_proj(x)\n",
    "        return x  # Shape: (batch_size, src_len, inst_size)\n",
    "\n",
    "class InstNormEncoder(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, num_layers, vocab_size, inst_size, max_len, dropout=0.1):\n",
    "        super(InstEncoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model//2)\n",
    "        self.norm_pos = nn.Embedding(100, d_model//2)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.inst_proj = nn.Linear(d_model, inst_size)\n",
    "        \n",
    "    def generate_src_mask(self, src):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        return (src != 0).unsqueeze(1).unsqueeze(2)  # Shape: (batch_size, 1, 1, src_len)\n",
    "\n",
    "    def forward(self, src, src_mask=None):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        x = self.embedding(src)  # Embedding\n",
    "        norm_pos = self.embedding()\n",
    "        # x shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        \n",
    "        # x = self.positional_encoding(x)\n",
    "        x = self.dropout(x)\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        x = self.inst_proj(x)\n",
    "        return x  # Shape: (batch_size, src_len, inst_size)\n",
    "\n",
    "class InstTransformer(nn.Module):\n",
    "    def __init__(self, device='cpu', d_model=768, num_heads=8, d_ff=2048, num_layers=6, max_len=5000, dropout=0.1):\n",
    "        super(InstTransformer, self).__init__()\n",
    "        self.device = device\n",
    "        self.chord_encoder = GPT2Model(vocab_size=150)\n",
    "        self.chord_encoder.load_state_dict(torch.load('/workspace/out/chord_bpe/GPT2_BPE_V150/model_207_0.4520_0.3645.pt'))\n",
    "        # Freeze the chord_transformer parameters\n",
    "        for param in self.chord_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.inst_embedding = nn.Embedding(133, 768)\n",
    "        self.init_inst_bos_proj = nn.Linear(133, 768)\n",
    "        \n",
    "        self.decoder = InstDecoder(d_model, num_heads, d_ff, num_layers, max_len, dropout)\n",
    "        \n",
    "        self.out = nn.Linear(d_model, 1)\n",
    "\n",
    "    def forward(self, chord_tensor, init_inst_tensor, inst_idx):\n",
    "        memory = self.chord_encoder(chord_tensor, return_hidden_states=True)\n",
    "        \n",
    "        length = memory.shape[1] - 2\n",
    "        \n",
    "        init_inst_embed = self.init_inst_bos_proj(init_inst_tensor)\n",
    "        init_inst_embed = init_inst_embed.unsqueeze(1).repeat(1, 1, 1)\n",
    "        \n",
    "        # out_embed = self.inst_poolers[inst_idx](input_embed)\n",
    "        inst_idx = torch.tensor([inst_idx]).to(self.device)\n",
    "        # print(inst_idx.shape)\n",
    "        inst_embed = self.inst_embedding(inst_idx)\n",
    "        inst_embed = inst_embed.unsqueeze(1).repeat(1, length-1, 1)\n",
    "        # print(inst_embed.shape)\n",
    "        decoder_input_embed = torch.cat((init_inst_embed, inst_embed), dim=1)\n",
    "        # print(decoder_input_embed.shape)\n",
    "        decoder_output = self.decoder(decoder_input_embed, memory)\n",
    "        \n",
    "        out_embed = self.out(decoder_output)\n",
    "        \n",
    "        return out_embed\n",
    "    \n",
    "    def infer(self, chord_tensor, init_inst_tensor):\n",
    "        # src shape: (batch_size, src_len)\n",
    "        # tgt shape: (batch_size, tgt_len)\n",
    "        \n",
    "        # src_mask = self.generate_src_mask(src)  # Generate source mask\n",
    "        # tgt_mask = self.generate_tgt_mask(tgt)  # Generate target mask\n",
    "\n",
    "        memory = self.chord_encoder(chord_tensor, return_hidden_states=True)  # Encoder output\n",
    "        # memory shape: (batch_size, src_len, d_model)\n",
    "        \n",
    "        length = memory.shape[1] - 2\n",
    "        \n",
    "        init_inst_embed = self.init_inst_bos_proj(init_inst_tensor)\n",
    "        init_inst_embed = init_inst_embed.unsqueeze(1).repeat(1, 1, 1)\n",
    "        \n",
    "        output_container = []\n",
    "        \n",
    "        for inst_idx in range(133):\n",
    "            # out_embed = self.inst_poolers[inst_idx](input_embed)\n",
    "            inst_idx = torch.tensor([inst_idx]).to(self.device)\n",
    "            # print(inst_idx.shape)\n",
    "            inst_embed = self.inst_embedding(inst_idx)\n",
    "            inst_embed = inst_embed.unsqueeze(1).repeat(1, length-1, 1)\n",
    "            # print(inst_embed.shape)\n",
    "            decoder_input_embed = torch.cat((init_inst_embed, inst_embed), dim=1)\n",
    "            # print(decoder_input_embed.shape)\n",
    "            decoder_output = self.decoder(decoder_input_embed, memory)\n",
    "            \n",
    "            out_embed = self.out(decoder_output)\n",
    "            \n",
    "            output_container.append(out_embed)\n",
    "        \n",
    "        return output_container\n",
    "    \n",
    "class GPT2Model(nn.Module):\n",
    "    def __init__(self, vocab_size=140, n_embd=768, n_layer=12, n_head=12):\n",
    "        super(GPT2Model, self).__init__()\n",
    "        self.configuration = GPT2Config(vocab_size=vocab_size, n_embd=n_embd, n_layer=n_layer, n_head=n_head, bos_token_id=2, eos_token_id=1)\n",
    "        self.model = GPT2LMHeadModel(self.configuration)\n",
    "        \n",
    "    def get_embed(self, idx):\n",
    "        embedding_layer = self.model.transformer.wte\n",
    "        token_embedding = embedding_layer(torch.tensor([idx]))\n",
    "        return token_embedding\n",
    "    \n",
    "    def extract_vocab_embeddings(self):\n",
    "        # Extract all the embeddings for the entire vocabulary\n",
    "        embedding_layer = self.model.transformer.wte\n",
    "        vocab_embeddings = embedding_layer.weight.detach().clone()\n",
    "        return vocab_embeddings\n",
    "\n",
    "    def forward(self, input_ids, labels=None, return_hidden_states=False):\n",
    "        attention_mask = self.make_mask(input_ids)\n",
    "        # Forward pass through the transformer to get hidden states\n",
    "        transformer_outputs = self.model.transformer(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "\n",
    "        # Extract hidden states before the projection\n",
    "        hidden_states = transformer_outputs.last_hidden_state\n",
    "        \n",
    "        if return_hidden_states:\n",
    "            return hidden_states\n",
    "\n",
    "        # Project the hidden states to vocabulary size\n",
    "        logits = self.model.lm_head(hidden_states)\n",
    "\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.configuration.vocab_size), labels.view(-1))\n",
    "            return loss, logits\n",
    "        return logits\n",
    "\n",
    "    def make_mask(self, input_ids):\n",
    "        attention_mask = (input_ids != 0).long()\n",
    "        return attention_mask\n",
    "    \n",
    "    def infer(self, input_ids, length=2048):\n",
    "        if len(input_ids.shape) == 1:\n",
    "            input_ids = input_ids.unsqueeze(0)\n",
    "        if len(input_ids.shape) > 2:\n",
    "            raise Exception\n",
    "        \n",
    "        if length > 2048:\n",
    "            print(\"Max Length is 2048. Change Length Auto to 2048\")\n",
    "            length = 2048\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(length):\n",
    "                logits = self.forward(input_ids)\n",
    "                output = torch.argmax(logits, dim=2)\n",
    "\n",
    "                predict = output[:,-1].unsqueeze(1)\n",
    "                output_ids = torch.cat((input_ids, predict), dim=-1)\n",
    "\n",
    "                input_ids = output_ids\n",
    "                \n",
    "                if output_ids.shape[1] > 2048:\n",
    "                    break\n",
    "\n",
    "        return output_ids\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_features, out_features)\n",
    "        # self.norm1 = nn.BatchNorm1d(out_features)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(out_features, out_features)\n",
    "        # self.norm2 = nn.BatchNorm1d(out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.linear1(x)\n",
    "        # out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        # out = self.norm2(out)\n",
    "        out += residual  # Add the residual connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class C2ITransformer(nn.Module):\n",
    "    def __init__(self, mode='proj'):\n",
    "        super(C2ITransformer, self).__init__()\n",
    "        \n",
    "        self.chord_encoder = GPT2Model(vocab_size=150)\n",
    "        self.chord_encoder.load_state_dict(torch.load('/workspace/out/chord_bpe/GPT2_BPE_V150/model_207_0.4520_0.3645.pt'))\n",
    "        # Freeze the chord_transformer parameters\n",
    "        for param in self.chord_encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.mode = mode\n",
    "        \n",
    "        self.hidden_map = nn.Sequential(\n",
    "            nn.Linear(768, 256),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(256, 256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            ResidualBlock(128,128),\n",
    "            nn.Linear(128,133)\n",
    "        )\n",
    "            \n",
    "    \n",
    "    def forward(self, chord_tensor):\n",
    "        # Encoder\n",
    "        chord_embedding = self.chord_encoder(chord_tensor, return_hidden_states=True)\n",
    "        \n",
    "        if self.mode == 'avg':\n",
    "            pass\n",
    "        \n",
    "        elif self.mode == 'bos':\n",
    "            chord_tensor = chord_embedding[:,0,:]\n",
    "            \n",
    "            output = self.hidden_map(chord_tensor)\n",
    "            output = torch.sigmoid(output)\n",
    "            return output\n",
    "        \n",
    "    def jaccard_loss(self, pred, target):\n",
    "        eps = 1e-10\n",
    "\n",
    "        intersection = torch.sum(pred * target)\n",
    "        union = torch.sum(pred) + torch.sum(target) - intersection\n",
    "        sim = (intersection + eps) / (union + eps)\n",
    "        return 1 - sim\n",
    "    \n",
    "    def hamming_loss(self, y_pred, y_true):\n",
    "        \n",
    "        # 이진화 없이 차이 계산 (torch.abs 사용)\n",
    "        hamming_distance = torch.sum(torch.abs(y_true - y_pred))\n",
    "        \n",
    "        # 벡터 길이로 나누어 해밍 손실 계산\n",
    "        hamming_loss = hamming_distance / y_true.numel()\n",
    "        return hamming_loss\n",
    "    \n",
    "    def bce_loss(self, logits, targets):\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "        loss = criterion(logits, targets)\n",
    "        return loss\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class InstDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/data/vocabs/inst.json'\n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_in_measure.append(t4)\n",
    "                \n",
    "            if (t1[0] == 'm' or t1[0] == 'M') and len(chord_list) > 0:\n",
    "                inst_list.append(inst_in_measure)\n",
    "                inst_in_measure = []\n",
    "        inst_list.append(inst_in_measure)\n",
    "        \n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        inst_tensor, length = self.convert_inst_to_onehot(inst_list)\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        target_inst_tensor = inst_tensor\n",
    "\n",
    "        return target_chord_tensor, target_inst_tensor, length+2\n",
    "    \n",
    "    def convert_inst_to_onehot(self, inst_list):\n",
    "        base_tensor = torch.zeros(len(inst_list), 133)\n",
    "        bos_tensor = torch.zeros(1, 133)\n",
    "        eos_tensor = torch.zeros(1, 133)\n",
    "        bos_tensor[:,2] = 1\n",
    "        eos_tensor[:,1] = 1\n",
    "        \n",
    "        for idx, inst_in_measure in enumerate(inst_list):\n",
    "            if len(inst_in_measure) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for inst in inst_in_measure:\n",
    "                    base_tensor[idx, self.inst_vocab[inst]] = 1\n",
    "        inst_tensor = torch.cat((bos_tensor,base_tensor[:766,:],eos_tensor), dim=0)\n",
    "        return inst_tensor, len(inst_list)\n",
    "  \n",
    "class InstGroupDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/data/vocabs/inst_group60_vocab.json'\n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_in_measure.append(t4)\n",
    "                \n",
    "            if (t1[0] == 'm' or t1[0] == 'M') and len(chord_list) > 0:\n",
    "                inst_list.append(inst_in_measure)\n",
    "                inst_in_measure = []\n",
    "        inst_list.append(inst_in_measure)\n",
    "        \n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        inst_tensor, length = self.convert_inst_to_onehot(inst_list)\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:510] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        target_inst_tensor = [2] + inst_tensor[:510] + [1]\n",
    "        length = len(target_inst_tensor)\n",
    "        target_inst_tensor = torch.tensor(target_inst_tensor)\n",
    "\n",
    "        return target_chord_tensor, target_inst_tensor, torch.tensor([length])\n",
    "    \n",
    "    def convert_inst_to_onehot(self, inst_list):\n",
    "        inst_vocab = []\n",
    "        \n",
    "        for insts in inst_list:\n",
    "            group_inst = ''\n",
    "            for inst in insts:\n",
    "                if inst in group_inst:\n",
    "                    pass\n",
    "                else:\n",
    "                    group_inst += inst\n",
    "            \n",
    "            try:\n",
    "                inst_vocab.append(self.inst_vocab[group_inst])\n",
    "            except:\n",
    "                inst_vocab.append(3)\n",
    "                \n",
    "        return inst_vocab, len(inst_list)\n",
    "    \n",
    "class C2IDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/data/vocabs/inst.json'\n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        \n",
    "        inst_tensor = torch.zeros(133)\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_tensor[self.inst_vocab[t4]] = 1\n",
    "        \n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        target_inst_tensor = inst_tensor\n",
    "\n",
    "        return target_chord_tensor, target_inst_tensor, torch.tensor([target_chord_tensor.shape[0]])\n",
    "    \n",
    "class InstGRUDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/data/vocabs/inst.json'\n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        ans_inst_container = []\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        inst_tensor = torch.zeros(133)\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'h' or t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_tensor[self.inst_vocab[t4]] = 1\n",
    "                \n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_in_measure.append(t4)\n",
    "                \n",
    "            if (t1[0] == 'm' or t1[0] == 'M') and len(chord_list) > 0:\n",
    "                inst_list.append(inst_in_measure)\n",
    "                inst_in_measure = []\n",
    "        \n",
    "        inst_list.append(inst_in_measure)\n",
    "\n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        ans_inst_container = self.convert_inst_to_onehot(inst_list, ans_inst_container)\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        init_inst_tensor = inst_tensor\n",
    "\n",
    "        return target_chord_tensor, init_inst_tensor, ans_inst_container\n",
    "    \n",
    "    def convert_inst_to_onehot(self, inst_list, ans_inst_container):\n",
    "        \n",
    "        for _ in range(133):\n",
    "            ans_inst_container.append([0]*len(inst_list))\n",
    "        \n",
    "        for idx, inst_in_measure in enumerate(inst_list):\n",
    "            if len(inst_in_measure) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for inst in inst_in_measure:\n",
    "                    # base_tensor[idx, self.inst_vocab[inst]] = 1\n",
    "                    ans_inst_container[self.inst_vocab[inst]][idx] = 1\n",
    "                    \n",
    "        for idx, vec in enumerate(ans_inst_container):\n",
    "            ans_inst_container[idx] = torch.tensor(vec[:766])\n",
    "        \n",
    "        return ans_inst_container\n",
    "   \n",
    "class InstVAEDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/data/vocabs/inst.json'\n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        init_instruments = [0]*133\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_in_measure.append(t4)\n",
    "                \n",
    "                init_instruments[self.inst_vocab[t4]] = 1\n",
    "                \n",
    "            if (t1[0] == 'm' or t1[0] == 'M') and len(chord_list) > 0:\n",
    "                inst_list.append(inst_in_measure)\n",
    "                inst_in_measure = []\n",
    "        inst_list.append(inst_in_measure)\n",
    "        \n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        inst_tensor, length = self.convert_inst_to_onehot(inst_list)\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        target_init_inst_tensor = torch.tensor(init_instruments)\n",
    "        \n",
    "        target_inst_tensor = inst_tensor\n",
    "\n",
    "        return target_chord_tensor, target_init_inst_tensor, target_inst_tensor, length\n",
    "    \n",
    "    def convert_inst_to_onehot(self, inst_list):\n",
    "        base_tensor = torch.zeros(len(inst_list), 133)\n",
    "        \n",
    "        for idx, inst_in_measure in enumerate(inst_list):\n",
    "            if len(inst_in_measure) == 0:\n",
    "                continue\n",
    "            else:\n",
    "                for inst in inst_in_measure:\n",
    "                    base_tensor[idx, self.inst_vocab[inst]] = 1\n",
    "        inst_tensor = base_tensor[:766,:]\n",
    "        return inst_tensor, len(inst_tensor)\n",
    "    \n",
    "def create_dataloaders(batch_size):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    # train, val_test = train_test_split(raw_data, test_size=0.5, random_state=5)\n",
    "    # val, test = train_test_split(val_test, test_size=0.2)\n",
    "    \n",
    "    train_dataset = InstDataset(train)\n",
    "    val_dataset = InstDataset(val)\n",
    "    test_dataset = InstDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch(batch):\n",
    "    chords, insts, length = zip(*batch)\n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(insts, padding_value=0, batch_first=True)\n",
    "    length_padded = pad_sequence(length, padding_value=0, batch_first=True)\n",
    "    return chord_padded, inst_padded, length_padded\n",
    "\n",
    "def create_C2I(batch_size):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = C2IDataset(train)\n",
    "    val_dataset = C2IDataset(val)\n",
    "    test_dataset = C2IDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch_C2I(batch):\n",
    "    chords, insts, length = zip(*batch)\n",
    "    \n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(insts, padding_value=0, batch_first=True)\n",
    "    length_padded = pad_sequence(length, padding_value=0, batch_first=True)\n",
    "\n",
    "    return chord_padded, inst_padded, length_padded\n",
    "\n",
    "\n",
    "def create_Group(batch_size):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = InstGroupDataset(train)\n",
    "    val_dataset = InstGroupDataset(val)\n",
    "    test_dataset = InstGroupDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch_Group)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_Group)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch_Group)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch_Group(batch):\n",
    "    chords, insts, length = zip(*batch)\n",
    "    \n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(insts, padding_value=0, batch_first=True)\n",
    "    length_padded = pad_sequence(length, padding_value=0, batch_first=True)\n",
    "\n",
    "    return chord_padded, inst_padded, length_padded\n",
    "\n",
    "def create_InstGRU(batch_size):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = InstGRUDataset(train)\n",
    "    val_dataset = InstGRUDataset(val)\n",
    "    test_dataset = InstGRUDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch_InstGRU)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_InstGRU)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch_InstGRU)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch_InstGRU(batch):\n",
    "    target_chord_tensor, init_inst_tensor, ans_inst_container = zip(*batch)\n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(target_chord_tensor, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(init_inst_tensor, padding_value=0, batch_first=True)\n",
    "    # ans_padded = pad_sequence(ans_inst_container, padding_value=0, batch_first=True)\n",
    "\n",
    "    return chord_padded, inst_padded, ans_inst_container\n",
    "\n",
    "\n",
    "def create_VAE(batch_size):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = InstVAEDataset(train)\n",
    "    val_dataset = InstVAEDataset(val)\n",
    "    test_dataset = InstVAEDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch_VAE)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_VAE)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch_VAE)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch_VAE(batch):\n",
    "    target_chord_tensor, target_init_inst_tensor, target_inst_tensor, length = zip(*batch)\n",
    "    chord_padded = pad_sequence(target_chord_tensor, padding_value=0, batch_first=True)\n",
    "    init_padded = pad_sequence(target_init_inst_tensor, padding_value=155, batch_first=True)\n",
    "    inst_padded = pad_sequence(target_inst_tensor, padding_value=0, batch_first=True)\n",
    "    # length_padded = pad_sequence(length, padding_value=0, batch_first=True)\n",
    "    return chord_padded, init_padded, inst_padded, length\n",
    "\n",
    "\n",
    "# train_loader, val_loader, test_loader = create_VAE(3)\n",
    "# for chord, init, inst, length in train_loader:\n",
    "#     print(chord)\n",
    "#     print(chord.shape)\n",
    "#     print(init)\n",
    "#     print(init.shape)\n",
    "#     print(inst)\n",
    "#     print(inst.shape)\n",
    "    \n",
    "#     print(length)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading original txt file...: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading original txt file...: 46188it [00:11, 3992.26it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_C2I(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard_similarity(y_true, y_pred, eps=1e-10):\n",
    "    # 교집합: 두 텐서에서 1로 일치하는 부분\n",
    "    intersection = torch.sum(y_true * y_pred)\n",
    "    \n",
    "    # 합집합: 두 텐서에서 1이 나타나는 모든 위치\n",
    "    union = torch.sum(y_true) + torch.sum(y_pred) - intersection\n",
    "    \n",
    "    # 자카드 유사도 계산\n",
    "    jaccard_sim = (intersection + eps) / (union + eps)\n",
    "    return jaccard_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset_accuracy(output, target):\n",
    "    zero_zero, one_one, zero_one, one_zero, err = 0,0,0,0,0\n",
    "\n",
    "    for preds , targets in zip(output, target):\n",
    "        preds = torch.tensor(preds).to(device)\n",
    "        \n",
    "        targets = targets.long()\n",
    "        targets = targets.squeeze(0).to(device)\n",
    "   \n",
    "        try:\n",
    "            zero_zero += torch.sum(((targets == 0) & (preds == 0))).item()\n",
    "            zero_one += torch.sum(((targets == 0) & (preds == 1))).item()\n",
    "            one_zero += torch.sum(((targets == 1) & (preds == 0))).item()\n",
    "            one_one += torch.sum(((targets == 1) & (preds == 1))).item()\n",
    "        except:\n",
    "            err += 1\n",
    "    \n",
    "    return zero_zero, one_one, zero_one, one_zero, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tmp_subset_accuracy(output, target):\n",
    "    zero_zero, one_one, zero_one, one_zero, err = 0,0,0,0,0\n",
    "\n",
    "    for preds , targets in zip(output, target):\n",
    "        preds = torch.tensor(preds).to(device)\n",
    "        targets = targets.long()\n",
    "        targets = targets.squeeze(0).to(device)\n",
    "        \n",
    "        try:\n",
    "            zero_zero += torch.sum(((targets == 0) & (preds == 0))).item()\n",
    "            zero_one += torch.sum(((targets == 0) & (preds == 1))).item()\n",
    "            one_zero += torch.sum(((targets == 1) & (preds == 0))).item()\n",
    "            one_one += torch.sum(((targets == 1) & (preds == 1))).item()\n",
    "        except:\n",
    "            err += 1\n",
    "    \n",
    "    return zero_zero, one_one, zero_one, one_zero, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "924\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Initialize an empty list to store the lines\n",
    "gen_txt = []\n",
    "\n",
    "# Open the file in read mode\n",
    "with open('/workspace/out/short_answer_output.txt', 'r') as file:\n",
    "    # Read each line from the file\n",
    "    for line in file:\n",
    "        # Strip newline characters and add to the list\n",
    "        gen_txt.append(line.strip())\n",
    "\n",
    "# Print the list to verify its contents\n",
    "print(len(gen_txt))\n",
    "\n",
    "import ast\n",
    "inst_candidate_list = []\n",
    "sum_gen_inst = torch.zeros(133).long()\n",
    "\n",
    "for idx, gen in enumerate(gen_txt):\n",
    "    \n",
    "    try:\n",
    "        to_list = ast.literal_eval(gen)\n",
    "    except:\n",
    "        inst_candidate_list.append([])\n",
    "        continue\n",
    "        print(idx)\n",
    "        print(gen)\n",
    "    \n",
    "    inst_list = [0]*133\n",
    "    for seq in to_list:\n",
    "        if seq in inst_vocab.keys():\n",
    "            inst_list[inst_vocab[seq]] = 1\n",
    "    inst_candidate_list.append(inst_list)\n",
    "    sum_gen_inst += torch.tensor(inst_list).long()\n",
    "print(inst_list)\n",
    "print(inst_candidate_list[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_insts = []\n",
    "sum_target_insts = torch.zeros(133).long()\n",
    "cnt = 0\n",
    "for (chords, targets, lengths) in test_loader:\n",
    "    targets_insts.append(targets)\n",
    "    sum_target_insts += targets.squeeze(0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targets_insts)\n",
    "print(sum_target_insts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SymGen vs Target Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 453,   3,   2,   3,   3,   0,   8,   0,   6, 104,\n",
      "          1,  45,  51,  36,  30,   1,   0,   1,   5,   7,   0,   4,   5,   0,\n",
      "         17,  19,   0,  23,   1,   7,   8,   0,  20,  44,  37,   2,   1,   1,\n",
      "          2,   0, 260, 129, 214, 169,   9,  65,  88, 217, 424,  10,   5,   0,\n",
      "         49,   4,   0,   1, 376, 332, 254,   2, 444,  15,   2,   0,  12, 175,\n",
      "        134,  90, 272,  21, 271, 443, 101, 452,   9,   1,   0,   0,   1,   5,\n",
      "          3,   7,   0,   0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   1,\n",
      "          1,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   3,   0,   1,\n",
      "          1,   0,   0,   0,   1,   0,   0,   0,   0,   1,   0,   0,   0,   1,\n",
      "          0,   0,   0,   0,   0,   0, 396], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sum_symgen_inst = sum_gen_inst.to(device)\n",
    "print(sum_symgen_inst)\n",
    "# print(inst_candidate_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109080\n",
      "5029\n",
      "1397\n",
      "6322\n",
      "8\n",
      "0.3944932538437402\n"
     ]
    }
   ],
   "source": [
    "# print(bos_jac)\n",
    "z_z, o_o, extra, lack, err = tmp_subset_accuracy(inst_candidate_list, targets_insts)\n",
    "# Symgen 생성과 Target Answer 비교\n",
    "print(z_z)\n",
    "print(o_o)\n",
    "print(extra)\n",
    "print(lack)\n",
    "print(err)\n",
    "print(o_o / (o_o+extra+lack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(371.2337, device='cuda:0')\n",
      "916\n",
      "tensor(0.4053, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Jaccard sim - 1 에 가까울수록 유사함\n",
    "jarc = 0\n",
    "cnt = 0\n",
    "for i, t in zip(inst_candidate_list, targets_insts):\n",
    "    preds = torch.tensor(i).to(device)\n",
    "    targets = t.squeeze(0).to(device)\n",
    "    try:\n",
    "        jar = jaccard_similarity(preds, targets)\n",
    "        jarc += jar\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "print(jarc)\n",
    "print(cnt)\n",
    "print(jarc/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 506,  18,   6,   7,  16,   1,  22,   0,  20, 252,\n",
      "         13, 124, 111, 103, 126,   2,   4,   5,   7,  32,   6,  13,  16,   0,\n",
      "         36,  34,  10,  37,   4,  19,  19,   5,  91,  71,  44,   6,   4,   4,\n",
      "          8,   5, 355, 200, 274, 268,  16, 160, 196, 521, 382,  12,  22,   3,\n",
      "        126,  12,   3,   3, 712, 614, 510,  32, 676,  39,  12,   3,  42, 325,\n",
      "        293, 229, 548,  71, 492, 679, 259, 765,  19,  11,   2,   1,   6,   7,\n",
      "         15,  15,   1,   2,   0,   3,   0,   4,   4,   8,   4,   1,   1,   1,\n",
      "          4,   1,   0,   2,   2,   3,   5,   0,   1,   2,   0,  10,   2,   2,\n",
      "          2,   2,   2,   2,   9,   0,   0,   3,   3,   5,   0,   2,   0,   0,\n",
      "          0,   0,   0,   1,   0,   0, 610], device='cuda:0')\n",
      "tensor([   0,    0,    0,    0,  -53,  -15,   -4,   -4,  -13,   -1,  -14,    0,\n",
      "         -14, -148,  -12,  -79,  -60,  -67,  -96,   -1,   -4,   -4,   -2,  -25,\n",
      "          -6,   -9,  -11,    0,  -19,  -15,  -10,  -14,   -3,  -12,  -11,   -5,\n",
      "         -71,  -27,   -7,   -4,   -3,   -3,   -6,   -5,  -95,  -71,  -60,  -99,\n",
      "          -7,  -95, -108, -304,   42,   -2,  -17,   -3,  -77,   -8,   -3,   -2,\n",
      "        -336, -282, -256,  -30, -232,  -24,  -10,   -3,  -30, -150, -159, -139,\n",
      "        -276,  -50, -221, -236, -158, -313,  -10,  -10,   -2,   -1,   -5,   -2,\n",
      "         -12,   -8,   -1,   -2,    0,   -3,    0,   -2,   -4,   -8,   -4,   -1,\n",
      "          -1,    0,   -3,   -1,    0,   -2,   -2,   -2,   -4,    0,   -1,   -2,\n",
      "           0,   -7,   -2,   -1,   -1,   -2,   -2,   -2,   -8,    0,    0,   -3,\n",
      "          -3,   -4,    0,   -2,    0,    1,    0,    0,    0,   -1,    0,    0,\n",
      "        -214], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sum_target_insts = sum_target_insts.to(device)\n",
    "print(sum_target_insts)\n",
    "print(sum_symgen_inst - sum_target_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015124751254916191\n"
     ]
    }
   ],
   "source": [
    "# JS divergence - 0일수록 동일한 분포\n",
    "\n",
    "infer = sum_symgen_inst / sum_symgen_inst.sum()\n",
    "# infer = sum_gen_inst\n",
    "target = (sum_target_insts / sum_target_insts.sum()).to(device)\n",
    "# target = sum_target_insts\n",
    "M = 0.5 * (infer + target)\n",
    "# print(infer)\n",
    "# print(target)\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10  # 작은 상수\n",
    "    return torch.sum(p * torch.log((p + epsilon) / (q + epsilon)))\n",
    "\n",
    "js_div = 0.5*kl_divergence(infer, M) + 0.5*kl_divergence(target, M)\n",
    "js_div = js_div.item()\n",
    "print(js_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "indices = range(len(sum_symgen_inst))\n",
    "width = 0.5  # Bar width\n",
    "\n",
    "plt.bar([i - width/2 for i in indices], sum_symgen_inst.cpu().detach().numpy(), width=width, label='SymGen')\n",
    "plt.bar([i + width/2 for i in indices], sum_target_insts.cpu().detach().numpy(), width=width, label='Test Set')\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Element Value')\n",
    "plt.title('Comparison of Two Datasets (Data 1 vs Data 2)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model loading - Avg 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/workspace/out/inst_pre'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "vocab_size = 150\n",
    "num_epochs = 500\n",
    "max_len=5000\n",
    "dropout=0.1\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = d_model*4\n",
    "num_layers = 8\n",
    "model = C2IEncoder(d_model=d_model, num_heads=num_heads, d_ff=d_ff, num_layers=num_layers, vocab_size=vocab_size, max_len=max_len, dropout=0.1)\n",
    "\n",
    "model.load_state_dict(torch.load(prefix + '/Avg_1/model_63_0.9724_0.4597_0.4386.pt', map_location=device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                               | 0/924 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 924/924 [00:49<00:00, 18.49it/s]\n"
     ]
    }
   ],
   "source": [
    "avg1 = []\n",
    "sum_avg1_jac = torch.zeros(133).long().to(device)\n",
    "for (chords, targets, lengths) in tqdm(test_loader, ncols=60):\n",
    "    chords = chords.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    outputs = model(chords)\n",
    "    outputs = model.avg_inst(outputs)\n",
    "    item = (outputs > 0.5).long().squeeze(0)\n",
    "    sum_avg1_jac += item.squeeze(0).long()\n",
    "    avg1.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 573,   4,   0,   3,   1,   1,   8,   0,   5, 203,\n",
      "          1,  72,  77,  66,  89,   0,   1,   1,   3,  10,   0,   2,   5,   0,\n",
      "         13,  16,   4,  21,   0,   6,   5,   0,  50,  50,  23,   2,   1,   0,\n",
      "          0,   1, 281, 179, 287, 217,   3, 142, 142, 585, 369,   7,   8,   0,\n",
      "         70,   4,   0,   0, 756, 656, 509,  11, 706,  13,   2,   1,  19, 279,\n",
      "        259, 214, 590,  25, 520, 695, 218, 834,   3,   2,   0,   0,   1,   4,\n",
      "          2,   4,   0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   1,\n",
      "          0,   0,   0,   1,   0,   2,   1,   0,   0,   1,   0,   6,   0,   1,\n",
      "          0,   0,   0,   0,   2,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 679], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg1_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1004/931628323.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(preds).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107509\n",
      "6689\n",
      "3942\n",
      "4752\n",
      "0\n",
      "0.434830657219008\n"
     ]
    }
   ],
   "source": [
    "# print(bos_jac)\n",
    "z_z, o_o, extra, lack, err = subset_accuracy(avg1, targets_insts)\n",
    "# Symgen 생성과 Target Answer 비교\n",
    "print(z_z)\n",
    "print(o_o)\n",
    "print(extra)\n",
    "print(lack)\n",
    "print(err)\n",
    "print(o_o / (o_o+extra+lack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1004/4177427347.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(i).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(412.5208, device='cuda:0')\n",
      "924\n",
      "tensor(0.4465, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Jaccard sim - 1 에 가까울수록 유사함\n",
    "jarc = 0\n",
    "cnt = 0\n",
    "for i, t in zip(avg1, targets_insts):\n",
    "    preds = torch.tensor(i).to(device)\n",
    "    targets = t.squeeze(0).to(device)\n",
    "    try:\n",
    "        jar = jaccard_similarity(preds, targets)\n",
    "        jarc += jar\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "print(jarc)\n",
    "print(cnt)\n",
    "print(jarc/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 573,   4,   0,   3,   1,   1,   8,   0,   5, 203,\n",
      "          1,  72,  77,  66,  89,   0,   1,   1,   3,  10,   0,   2,   5,   0,\n",
      "         13,  16,   4,  21,   0,   6,   5,   0,  50,  50,  23,   2,   1,   0,\n",
      "          0,   1, 281, 179, 287, 217,   3, 142, 142, 585, 369,   7,   8,   0,\n",
      "         70,   4,   0,   0, 756, 656, 509,  11, 706,  13,   2,   1,  19, 279,\n",
      "        259, 214, 590,  25, 520, 695, 218, 834,   3,   2,   0,   0,   1,   4,\n",
      "          2,   4,   0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   1,\n",
      "          0,   0,   0,   1,   0,   2,   1,   0,   0,   1,   0,   6,   0,   1,\n",
      "          0,   0,   0,   0,   2,   0,   1,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 679], device='cuda:0')\n",
      "tensor([  0,   0,   0,   0,  67, -14,  -6,  -4, -15,   0, -14,   0, -15, -49,\n",
      "        -12, -52, -34, -37, -37,  -2,  -3,  -4,  -4, -22,  -6, -11, -11,   0,\n",
      "        -23, -18,  -6, -16,  -4, -13, -14,  -5, -41, -21, -21,  -4,  -3,  -4,\n",
      "         -8,  -4, -74, -21,  13, -51, -13, -18, -54,  64, -13,  -5, -14,  -3,\n",
      "        -56,  -8,  -3,  -3,  44,  42,  -1, -21,  30, -26, -10,  -2, -23, -46,\n",
      "        -34, -15,  42, -46,  28,  16, -41,  69, -16,  -9,  -2,  -1,  -5,  -3,\n",
      "        -13, -11,  -1,  -2,   0,  -3,   0,  -3,  -4,  -7,  -4,  -1,  -1,   0,\n",
      "         -4,  -1,   0,  -1,  -2,  -1,  -4,   0,  -1,  -1,   0,  -4,  -2,  -1,\n",
      "         -2,  -2,  -2,  -2,  -7,   0,   1,  -3,  -3,  -5,   0,  -2,   0,   0,\n",
      "          0,   0,   0,  -1,   0,   0,  69], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg1_jac)\n",
    "print(sum_avg1_jac - sum_target_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011948337778449059\n"
     ]
    }
   ],
   "source": [
    "# JS divergence - 0일수록 동일한 분포\n",
    "\n",
    "infer = sum_avg1_jac / sum_avg1_jac.sum()\n",
    "# infer = sum_gen_inst\n",
    "target = (sum_target_insts / sum_target_insts.sum()).to(device)\n",
    "# target = sum_target_insts\n",
    "M = 0.5 * (infer + target)\n",
    "# print(infer)\n",
    "# print(target)\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10  # 작은 상수\n",
    "    return torch.sum(p * torch.log((p + epsilon) / (q + epsilon)))\n",
    "\n",
    "js_div = 0.5*kl_divergence(infer, M) + 0.5*kl_divergence(target, M)\n",
    "js_div = js_div.item()\n",
    "print(js_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "indices = range(len(sum_symgen_inst))\n",
    "width = 0.6  # Bar width\n",
    "\n",
    "plt.bar([i - width/2 for i in indices], sum_avg1_jac.cpu().detach().numpy(), width=width, label='SymGen')\n",
    "plt.bar([i + width/2 for i in indices], sum_target_insts.cpu().detach().numpy(), width=width, label='Test Set')\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Element Value')\n",
    "plt.title('Comparison of Two Datasets (Data 1 vs Data 2)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avg + Len compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/workspace/out/inst_pre'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "vocab_size = 150\n",
    "num_epochs = 500\n",
    "max_len=5000\n",
    "dropout=0.1\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = d_model*4\n",
    "num_layers = 8\n",
    "model = C2IEncoder(d_model=d_model, num_heads=num_heads, d_ff=d_ff, num_layers=num_layers, vocab_size=vocab_size, max_len=max_len, dropout=0.1, mode='len')\n",
    "\n",
    "model.load_state_dict(torch.load(prefix + '/Avg_LEN_1/model_8_0.4799_0.4555_0.4508.pt', map_location=device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 924/924 [00:46<00:00, 19.83it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_len = []\n",
    "sum_avg_len = torch.zeros(133).long().to(device)\n",
    "for (chords, targets, lengths) in tqdm(test_loader, ncols=60):\n",
    "    chords = chords.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    outputs = model(chords)\n",
    "    outputs = model.avg_inst(outputs, length=lengths.to(device))\n",
    "    item = (outputs > 0.5).long().squeeze(0)\n",
    "    sum_avg_len += item.squeeze(0).long()\n",
    "    avg_len.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 336,   0,   0,   0,   0,   0,   0,   0,   0,  41,\n",
      "          0,  15,  11,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
      "          0,   0,   8,   1,   2,   2,   0,   2,   4, 453,  83,   0,   1,   0,\n",
      "          0,   0,   0,   0, 852, 570, 427,   0, 734,   2,   0,   0,   0, 156,\n",
      "        102,  71, 486,   3, 347, 726,  41, 872,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 698], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1004/931628323.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(preds).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109510\n",
      "5116\n",
      "1941\n",
      "6325\n",
      "0\n",
      "0.382304588252877\n"
     ]
    }
   ],
   "source": [
    "# print(bos_jac)\n",
    "z_z, o_o, extra, lack, err = subset_accuracy(avg_len, targets_insts)\n",
    "# Symgen 생성과 Target Answer 비교\n",
    "print(z_z)\n",
    "print(o_o)\n",
    "print(extra)\n",
    "print(lack)\n",
    "print(err)\n",
    "print(o_o / (o_o+extra+lack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1004/3055259491.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(350.7721, device='cuda:0')\n",
      "924\n",
      "tensor(0.3796, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Jaccard sim - 1 에 가까울수록 유사함\n",
    "\n",
    "\n",
    "jarc = 0\n",
    "cnt = 0\n",
    "for i, t in zip(avg_len, targets_insts):\n",
    "    preds = torch.tensor(i)\n",
    "    targets = t.squeeze(0).to(device)\n",
    "    try:\n",
    "        jar = jaccard_similarity(preds, targets)\n",
    "        jarc += jar\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "print(jarc)\n",
    "print(cnt)\n",
    "print(jarc/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 336,   0,   0,   0,   0,   0,   0,   0,   0,  41,\n",
      "          0,  15,  11,  10,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,\n",
      "          0,   0,   8,   1,   2,   2,   0,   2,   4, 453,  83,   0,   1,   0,\n",
      "          0,   0,   0,   0, 852, 570, 427,   0, 734,   2,   0,   0,   0, 156,\n",
      "        102,  71, 486,   3, 347, 726,  41, 872,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 698], device='cuda:0')\n",
      "tensor([   0,    0,    0,    0, -170,  -18,   -6,   -7,  -16,   -1,  -22,    0,\n",
      "         -20, -211,  -13, -109, -100,  -93, -126,   -2,   -4,   -5,   -7,  -32,\n",
      "          -6,  -13,  -16,    0,  -36,  -34,  -10,  -37,   -4,  -19,  -19,   -5,\n",
      "         -90,  -71,  -44,   -6,   -4,   -4,   -8,   -5, -347, -199, -272, -266,\n",
      "         -16, -158, -192,  -68, -299,  -12,  -21,   -3, -126,  -12,   -3,   -3,\n",
      "         140,  -44,  -83,  -32,   58,  -37,  -12,   -3,  -42, -169, -191, -158,\n",
      "         -62,  -68, -145,   47, -218,  107,  -19,  -11,   -2,   -1,   -6,   -7,\n",
      "         -15,  -15,   -1,   -2,    0,   -3,    0,   -4,   -4,   -8,   -4,   -1,\n",
      "          -1,   -1,   -4,   -1,    0,   -2,   -2,   -3,   -5,    0,   -1,   -2,\n",
      "           0,  -10,   -2,   -2,   -2,   -2,   -2,   -2,   -9,    0,    0,   -3,\n",
      "          -3,   -5,    0,   -2,    0,    0,    0,    0,    0,   -1,    0,    0,\n",
      "          88], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)\n",
    "print(sum_avg_len - sum_target_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11265507340431213\n"
     ]
    }
   ],
   "source": [
    "# JS divergence - 0일수록 동일한 분포\n",
    "\n",
    "infer = sum_avg_len / sum_avg_len.sum()\n",
    "# infer = sum_gen_inst\n",
    "target = (sum_target_insts / sum_target_insts.sum()).to(device)\n",
    "# target = sum_target_insts\n",
    "M = 0.5 * (infer + target)\n",
    "# print(infer)\n",
    "# print(target)\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10  # 작은 상수\n",
    "    return torch.sum(p * torch.log((p + epsilon) / (q + epsilon)))\n",
    "\n",
    "js_div = 0.5*kl_divergence(infer, M) + 0.5*kl_divergence(target, M)\n",
    "js_div = js_div.item()\n",
    "print(js_div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16, 6))\n",
    "indices = range(len(sum_symgen_inst))\n",
    "width = 0.6  # Bar width\n",
    "\n",
    "plt.bar([i - width/2 for i in indices], sum_avg_len.cpu().detach().numpy(), width=width, label='SymGen')\n",
    "plt.bar([i + width/2 for i in indices], sum_target_insts.cpu().detach().numpy(), width=width, label='Test Set')\n",
    "\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Element Value')\n",
    "plt.title('Comparison of Two Datasets (Data 1 vs Data 2)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proj_1 + LEN Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/workspace/out/inst_pre'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "vocab_size = 150\n",
    "num_epochs = 500\n",
    "max_len=5000\n",
    "dropout=0.1\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = d_model*4\n",
    "num_layers = 8\n",
    "model = C2IEncoder(d_model=d_model, num_heads=num_heads, d_ff=d_ff, num_layers=num_layers, vocab_size=vocab_size, max_len=max_len, dropout=0.1)\n",
    "\n",
    "model.load_state_dict(torch.load(prefix + '/Proj_LEN_1/model_76_0.9807_0.4524_0.4397.pt', map_location=device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 924/924 [00:45<00:00, 20.40it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_len = []\n",
    "sum_avg_len = torch.zeros(133).long().to(device)\n",
    "for (chords, targets, lengths) in tqdm(test_loader, ncols=60):\n",
    "    chords = chords.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    outputs = model(chords)\n",
    "    outputs = model.proj_inst(outputs, length=lengths.to(device))\n",
    "    item = (outputs > 0.5).long().squeeze(0)\n",
    "    sum_avg_len += item.squeeze(0).long()\n",
    "    avg_len.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 508,   4,   2,   2,   2,   0,   7,   0,  10, 168,\n",
      "          1,  79,  50,  58,  75,   0,   1,   1,   1,   5,   1,   3,   4,   0,\n",
      "         11,   8,   8,  11,   2,   4,   6,   1,  72,  41,  19,   1,   0,   1,\n",
      "          0,   0, 323, 158, 240, 235,   7, 136, 118, 553, 359,   4,   8,   1,\n",
      "         73,   4,   0,   0, 755, 627, 526,  12, 698,  22,   3,   0,  22, 267,\n",
      "        224, 164, 613,  28, 492, 691, 195, 817,   4,   0,   0,   0,   1,   3,\n",
      "          1,   3,   0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   2,\n",
      "          0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   3,   0,   0,\n",
      "          0,   1,   0,   0,   2,   0,   2,   0,   2,   0,   0,   1,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 646], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107803\n",
      "6569\n",
      "3648\n",
      "4872\n",
      "0\n",
      "0.43535025515276027\n"
     ]
    }
   ],
   "source": [
    "# print(bos_jac)\n",
    "z_z, o_o, extra, lack, err = subset_accuracy(avg_len, targets_insts)\n",
    "# Symgen 생성과 Target Answer 비교\n",
    "print(z_z)\n",
    "print(o_o)\n",
    "print(extra)\n",
    "print(lack)\n",
    "print(err)\n",
    "print(o_o / (o_o+extra+lack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5645/3055259491.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(416.0846, device='cuda:0')\n",
      "924\n",
      "tensor(0.4503, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Jaccard sim - 1 에 가까울수록 유사함\n",
    "\n",
    "\n",
    "jarc = 0\n",
    "cnt = 0\n",
    "for i, t in zip(avg_len, targets_insts):\n",
    "    preds = torch.tensor(i)\n",
    "    targets = t.squeeze(0).to(device)\n",
    "    try:\n",
    "        jar = jaccard_similarity(preds, targets)\n",
    "        jarc += jar\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "print(jarc)\n",
    "print(cnt)\n",
    "print(jarc/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 508,   4,   2,   2,   2,   0,   7,   0,  10, 168,\n",
      "          1,  79,  50,  58,  75,   0,   1,   1,   1,   5,   1,   3,   4,   0,\n",
      "         11,   8,   8,  11,   2,   4,   6,   1,  72,  41,  19,   1,   0,   1,\n",
      "          0,   0, 323, 158, 240, 235,   7, 136, 118, 553, 359,   4,   8,   1,\n",
      "         73,   4,   0,   0, 755, 627, 526,  12, 698,  22,   3,   0,  22, 267,\n",
      "        224, 164, 613,  28, 492, 691, 195, 817,   4,   0,   0,   0,   1,   3,\n",
      "          1,   3,   0,   0,   0,   0,   0,   1,   0,   1,   0,   0,   0,   2,\n",
      "          0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   3,   0,   0,\n",
      "          0,   1,   0,   0,   2,   0,   2,   0,   2,   0,   0,   1,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 646], device='cuda:0')\n",
      "tensor([  0,   0,   0,   0, 506,  18,   6,   7,  16,   1,  22,   0,  20, 252,\n",
      "         13, 124, 111, 103, 126,   2,   4,   5,   7,  32,   6,  13,  16,   0,\n",
      "         36,  34,  10,  37,   4,  19,  19,   5,  91,  71,  44,   6,   4,   4,\n",
      "          8,   5, 355, 200, 274, 268,  16, 160, 196, 521, 382,  12,  22,   3,\n",
      "        126,  12,   3,   3, 712, 614, 510,  32, 676,  39,  12,   3,  42, 325,\n",
      "        293, 229, 548,  71, 492, 679, 259, 765,  19,  11,   2,   1,   6,   7,\n",
      "         15,  15,   1,   2,   0,   3,   0,   4,   4,   8,   4,   1,   1,   1,\n",
      "          4,   1,   0,   2,   2,   3,   5,   0,   1,   2,   0,  10,   2,   2,\n",
      "          2,   2,   2,   2,   9,   0,   0,   3,   3,   5,   0,   2,   0,   0,\n",
      "          0,   0,   0,   1,   0,   0, 610], device='cuda:0')\n",
      "tensor([  0,   0,   0,   0,   2, -14,  -4,  -5, -14,  -1, -15,   0, -10, -84,\n",
      "        -12, -45, -61, -45, -51,  -2,  -3,  -4,  -6, -27,  -5, -10, -12,   0,\n",
      "        -25, -26,  -2, -26,  -2, -15, -13,  -4, -19, -30, -25,  -5,  -4,  -3,\n",
      "         -8,  -5, -32, -42, -34, -33,  -9, -24, -78,  32, -23,  -8, -14,  -2,\n",
      "        -53,  -8,  -3,  -3,  43,  13,  16, -20,  22, -17,  -9,  -3, -20, -58,\n",
      "        -69, -65,  65, -43,   0,  12, -64,  52, -15, -11,  -2,  -1,  -5,  -4,\n",
      "        -14, -12,  -1,  -2,   0,  -3,   0,  -3,  -4,  -7,  -4,  -1,  -1,   1,\n",
      "         -4,  -1,   0,  -2,  -2,  -2,  -4,   0,  -1,  -2,   0,  -7,  -2,  -2,\n",
      "         -2,  -1,  -2,  -2,  -7,   0,   2,  -3,  -1,  -5,   0,  -1,   0,   0,\n",
      "          0,   0,   0,  -1,   0,   0,  36], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)\n",
    "sum_target_insts = sum_target_insts.to(device)\n",
    "print(sum_target_insts)\n",
    "print(sum_avg_len - sum_target_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012852976098656654\n"
     ]
    }
   ],
   "source": [
    "# JS divergence - 0일수록 동일한 분포\n",
    "\n",
    "infer = sum_avg_len / sum_avg_len.sum()\n",
    "# infer = sum_gen_inst\n",
    "target = (sum_target_insts / sum_target_insts.sum()).to(device)\n",
    "# target = sum_target_insts\n",
    "M = 0.5 * (infer + target)\n",
    "# print(infer)\n",
    "# print(target)\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10  # 작은 상수\n",
    "    return torch.sum(p * torch.log((p + epsilon) / (q + epsilon)))\n",
    "\n",
    "js_div = 0.5*kl_divergence(infer, M) + 0.5*kl_divergence(target, M)\n",
    "js_div = js_div.item()\n",
    "print(js_div)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proj_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = '/workspace/out/inst_pre'\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "vocab_size = 150\n",
    "num_epochs = 500\n",
    "max_len=5000\n",
    "dropout=0.1\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "d_ff = d_model*4\n",
    "num_layers = 8\n",
    "model = C2IEncoder(d_model=d_model, num_heads=num_heads, d_ff=d_ff, num_layers=num_layers, vocab_size=vocab_size, max_len=max_len, dropout=0.1)\n",
    "\n",
    "model.load_state_dict(torch.load(prefix + '/Proj_1/model_66_0.9659_0.4616_0.4460.pt', map_location=device))\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 924/924 [00:44<00:00, 20.69it/s]\n"
     ]
    }
   ],
   "source": [
    "avg_len = []\n",
    "sum_avg_len = torch.zeros(133).long().to(device)\n",
    "for (chords, targets, lengths) in tqdm(test_loader, ncols=60):\n",
    "    chords = chords.to(device)\n",
    "    targets = targets.to(device)\n",
    "    \n",
    "    outputs = model(chords)\n",
    "    outputs = model.proj_inst(outputs)\n",
    "    item = (outputs > 0.5).long().squeeze(0)\n",
    "    sum_avg_len += item.squeeze(0).long()\n",
    "    avg_len.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 540,   4,   1,   1,   1,   0,   3,   0,   8, 147,\n",
      "          5,  53,  53,  54,  58,   0,   1,   1,   3,  13,   2,   2,   3,   0,\n",
      "          8,  13,   1,  11,   0,   4,   8,   1,  27,  44,  22,   2,   1,   0,\n",
      "          0,   1, 293, 149, 228, 192,  11, 114, 141, 562, 403,   4,   8,   1,\n",
      "         69,   3,   0,   0, 769, 628, 510,   8, 732,  15,   2,   2,  15, 265,\n",
      "        176, 138, 612,  28, 459, 731, 221, 809,   8,   1,   0,   0,   1,   1,\n",
      "          0,   4,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   1,\n",
      "          0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   2,   0,   0,\n",
      "          0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 653], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107964\n",
      "6583\n",
      "3487\n",
      "4858\n",
      "0\n",
      "0.4409833869239014\n"
     ]
    }
   ],
   "source": [
    "# print(bos_jac)\n",
    "z_z, o_o, extra, lack, err = subset_accuracy(avg_len, targets_insts)\n",
    "# Symgen 생성과 Target Answer 비교\n",
    "print(z_z)\n",
    "print(o_o)\n",
    "print(extra)\n",
    "print(lack)\n",
    "print(err)\n",
    "print(o_o / (o_o+extra+lack))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(419.7626, device='cuda:0')\n",
      "924\n",
      "tensor(0.4543, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5645/3055259491.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  preds = torch.tensor(i)\n"
     ]
    }
   ],
   "source": [
    "# Jaccard sim - 1 에 가까울수록 유사함\n",
    "\n",
    "\n",
    "jarc = 0\n",
    "cnt = 0\n",
    "for i, t in zip(avg_len, targets_insts):\n",
    "    preds = torch.tensor(i)\n",
    "    targets = t.squeeze(0).to(device)\n",
    "    try:\n",
    "        jar = jaccard_similarity(preds, targets)\n",
    "        jarc += jar\n",
    "        cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "print(jarc)\n",
    "print(cnt)\n",
    "print(jarc/cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   0,   0,   0, 540,   4,   1,   1,   1,   0,   3,   0,   8, 147,\n",
      "          5,  53,  53,  54,  58,   0,   1,   1,   3,  13,   2,   2,   3,   0,\n",
      "          8,  13,   1,  11,   0,   4,   8,   1,  27,  44,  22,   2,   1,   0,\n",
      "          0,   1, 293, 149, 228, 192,  11, 114, 141, 562, 403,   4,   8,   1,\n",
      "         69,   3,   0,   0, 769, 628, 510,   8, 732,  15,   2,   2,  15, 265,\n",
      "        176, 138, 612,  28, 459, 731, 221, 809,   8,   1,   0,   0,   1,   1,\n",
      "          0,   4,   0,   0,   0,   0,   0,   1,   0,   0,   0,   0,   0,   1,\n",
      "          0,   0,   0,   0,   0,   1,   1,   0,   0,   0,   0,   2,   0,   0,\n",
      "          0,   0,   0,   0,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "          0,   0,   0,   0,   0,   0, 653], device='cuda:0')\n",
      "tensor([  0,   0,   0,   0, 506,  18,   6,   7,  16,   1,  22,   0,  20, 252,\n",
      "         13, 124, 111, 103, 126,   2,   4,   5,   7,  32,   6,  13,  16,   0,\n",
      "         36,  34,  10,  37,   4,  19,  19,   5,  91,  71,  44,   6,   4,   4,\n",
      "          8,   5, 355, 200, 274, 268,  16, 160, 196, 521, 382,  12,  22,   3,\n",
      "        126,  12,   3,   3, 712, 614, 510,  32, 676,  39,  12,   3,  42, 325,\n",
      "        293, 229, 548,  71, 492, 679, 259, 765,  19,  11,   2,   1,   6,   7,\n",
      "         15,  15,   1,   2,   0,   3,   0,   4,   4,   8,   4,   1,   1,   1,\n",
      "          4,   1,   0,   2,   2,   3,   5,   0,   1,   2,   0,  10,   2,   2,\n",
      "          2,   2,   2,   2,   9,   0,   0,   3,   3,   5,   0,   2,   0,   0,\n",
      "          0,   0,   0,   1,   0,   0, 610], device='cuda:0')\n",
      "tensor([   0,    0,    0,    0,   34,  -14,   -5,   -6,  -15,   -1,  -19,    0,\n",
      "         -12, -105,   -8,  -71,  -58,  -49,  -68,   -2,   -3,   -4,   -4,  -19,\n",
      "          -4,  -11,  -13,    0,  -28,  -21,   -9,  -26,   -4,  -15,  -11,   -4,\n",
      "         -64,  -27,  -22,   -4,   -3,   -4,   -8,   -4,  -62,  -51,  -46,  -76,\n",
      "          -5,  -46,  -55,   41,   21,   -8,  -14,   -2,  -57,   -9,   -3,   -3,\n",
      "          57,   14,    0,  -24,   56,  -24,  -10,   -1,  -27,  -60, -117,  -91,\n",
      "          64,  -43,  -33,   52,  -38,   44,  -11,  -10,   -2,   -1,   -5,   -6,\n",
      "         -15,  -11,   -1,   -2,    0,   -3,    0,   -3,   -4,   -8,   -4,   -1,\n",
      "          -1,    0,   -4,   -1,    0,   -2,   -2,   -2,   -4,    0,   -1,   -2,\n",
      "           0,   -8,   -2,   -2,   -2,   -2,   -2,   -2,   -7,    0,    0,   -3,\n",
      "          -3,   -5,    0,   -2,    0,    0,    0,    0,    0,   -1,    0,    0,\n",
      "          43], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(sum_avg_len)\n",
    "sum_target_insts = sum_target_insts.to(device)\n",
    "print(sum_target_insts)\n",
    "print(sum_avg_len - sum_target_insts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.015964534133672714\n"
     ]
    }
   ],
   "source": [
    "# JS divergence - 0일수록 동일한 분포\n",
    "\n",
    "infer = sum_avg_len / sum_avg_len.sum()\n",
    "# infer = sum_gen_inst\n",
    "target = (sum_target_insts / sum_target_insts.sum()).to(device)\n",
    "# target = sum_target_insts\n",
    "M = 0.5 * (infer + target)\n",
    "# print(infer)\n",
    "# print(target)\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10  # 작은 상수\n",
    "    return torch.sum(p * torch.log((p + epsilon) / (q + epsilon)))\n",
    "\n",
    "js_div = 0.5*kl_divergence(infer, M) + 0.5*kl_divergence(target, M)\n",
    "js_div = js_div.item()\n",
    "print(js_div)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
