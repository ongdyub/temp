{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class C2IDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        inst_vocab_path = '/workspace/pj/data/vocabs/inst.json'\n",
    "        chord_vocab_path = '/workspace/pj/data/vocabs/chord.json'\n",
    "        with open(inst_vocab_path, 'r') as file:\n",
    "            self.inst_vocab = json.load(file)\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "            \n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        chord_list = []\n",
    "        inst_in_measure = []\n",
    "        inst_list = []\n",
    "        \n",
    "        inst_tensor = torch.zeros(133)\n",
    "        \n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            if t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "\n",
    "            if t4[0] == 'x' or t4[0] == 'X' or t4[0] == 'y' or t4 == '<unk>':\n",
    "                inst_tensor[self.inst_vocab[t4]] = 1\n",
    "        \n",
    "        chord_tensor = [self.chord_vocab[chd] for chd in chord_list]\n",
    "        \n",
    "        target_chord_tensor = [2] + chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        target_inst_tensor = inst_tensor\n",
    "\n",
    "        return target_chord_tensor, target_inst_tensor, target_chord_tensor.shape[0]\n",
    "    \n",
    "def create_dataloaders(batch_size):\n",
    "    raw_data_path = '../../../workspace/pj/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    # train, val_test = train_test_split(raw_data, test_size=0.5, random_state=5)\n",
    "    # val, test = train_test_split(val_test, test_size=0.2)\n",
    "    \n",
    "    train_dataset = InstDataset(train)\n",
    "    val_dataset = InstDataset(val)\n",
    "    test_dataset = InstDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch(batch):\n",
    "    chords, insts, length = zip(*batch)\n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(insts, padding_value=0, batch_first=True)\n",
    "    length_padded = pad_sequence(length, padding_value=0, batch_first=True)\n",
    "    return chord_padded, inst_padded, length_padded\n",
    "\n",
    "def create_C2I(batch_size):\n",
    "    raw_data_path = '../../../workspace/pj/data/corpus/raw_corpus_bpe.txt'\n",
    "    # raw_data_path = '../../../workspace/data/corpus/first_5_lines_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = C2IDataset(train)\n",
    "    val_dataset = C2IDataset(val)\n",
    "    test_dataset = C2IDataset(test)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch_C2I)\n",
    "\n",
    "    # return train_loader, True, True\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch_C2I(batch):\n",
    "    chords, insts, length = zip(*batch)\n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    inst_padded = pad_sequence(insts, padding_value=0, batch_first=True)\n",
    "    return chord_padded, inst_padded, length\n",
    "\n",
    "torch.set_printoptions(profile=\"full\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading original txt file...: 46188it [00:11, 3875.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = create_C2I(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████| 41569/41569 [27:41<00:00, 25.03it/s]\n"
     ]
    }
   ],
   "source": [
    "inst_sum = torch.zeros(133).long()\n",
    "print(inst_sum)\n",
    "cnt = 0\n",
    "\n",
    "for (chords, targets, lengths) in tqdm(train_loader, ncols=60):\n",
    "    inst_sum += targets.squeeze(0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                              | 0/3695 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████| 3695/3695 [02:23<00:00, 25.67it/s]\n"
     ]
    }
   ],
   "source": [
    "for (chords, targets, lengths) in tqdm(val_loader, ncols=60):\n",
    "    inst_sum += targets.squeeze(0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                               | 0/924 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████| 924/924 [00:37<00:00, 24.73it/s]\n"
     ]
    }
   ],
   "source": [
    "for (chords, targets, lengths) in tqdm(test_loader, ncols=60):\n",
    "    inst_sum += targets.squeeze(0).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     0,     0,     0, 25758,   723,   300,   342,   709,   195,\n",
      "          862,   157,  1264, 11379,   730,  6129,  5857,  4921,  6224,   236,\n",
      "          285,   229,   289,  1565,   277,   728,   577,   122,  1843,  1734,\n",
      "          562,  2065,   415,   713,   652,   115,  4529,  3615,  2193,   355,\n",
      "          146,   145,   374,   227, 16963, 11370, 14240, 14010,  1379,  8758,\n",
      "         9241, 26186, 19252,  1011,  1029,   271,  6613,   450,   190,   208,\n",
      "        36920, 30527, 25915,  1596, 34516,  1553,   563,   225,  2156, 16172,\n",
      "        13834, 10948, 28672,  3767, 25725, 34334, 13628, 38641,   908,   579,\n",
      "          112,    94,   417,   567,   669,   675,   191,    84,    37,   180,\n",
      "           23,   358,   281,   268,   124,   251,   125,   120,   130,    92,\n",
      "          258,    66,    96,   154,   151,    55,    78,    85,   144,   427,\n",
      "           64,   192,   120,   206,   146,    39,   343,    15,   196,    58,\n",
      "          254,   244,    29,   232,    11,    29,    65,    20,    13,    19,\n",
      "           14,    52, 30432])\n"
     ]
    }
   ],
   "source": [
    "print(inst_sum.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([46188, 46188, 46188, 46188, 20430, 45465, 45888, 45846, 45479, 45993,\n",
      "        45326, 46031, 44924, 34809, 45458, 40059, 40331, 41267, 39964, 45952,\n",
      "        45903, 45959, 45899, 44623, 45911, 45460, 45611, 46066, 44345, 44454,\n",
      "        45626, 44123, 45773, 45475, 45536, 46073, 41659, 42573, 43995, 45833,\n",
      "        46042, 46043, 45814, 45961, 29225, 34818, 31948, 32178, 44809, 37430,\n",
      "        36947, 20002, 26936, 45177, 45159, 45917, 39575, 45738, 45998, 45980,\n",
      "         9268, 15661, 20273, 44592, 11672, 44635, 45625, 45963, 44032, 30016,\n",
      "        32354, 35240, 17516, 42421, 20463, 11854, 32560,  7547, 45280, 45609,\n",
      "        46076, 46094, 45771, 45621, 45519, 45513, 45997, 46104, 46151, 46008,\n",
      "        46165, 45830, 45907, 45920, 46064, 45937, 46063, 46068, 46058, 46096,\n",
      "        45930, 46122, 46092, 46034, 46037, 46133, 46110, 46103, 46044, 45761,\n",
      "        46124, 45996, 46068, 45982, 46042, 46149, 45845, 46173, 45992, 46130,\n",
      "        45934, 45944, 46159, 45956, 46177, 46159, 46123, 46168, 46175, 46169,\n",
      "        46174, 46136, 15756])\n"
     ]
    }
   ],
   "source": [
    "neg = 46188 - inst_sum\n",
    "print(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-9223372036854775808, -9223372036854775808, -9223372036854775808,\n",
      "        -9223372036854775808,                    0,                   62,\n",
      "                         152,                  134,                   64,\n",
      "                         235,                   52,                  293,\n",
      "                          35,                    3,                   62,\n",
      "                           6,                    6,                    8,\n",
      "                           6,                  194,                  161,\n",
      "                         200,                  158,                   28,\n",
      "                         165,                   62,                   79,\n",
      "                         377,                   24,                   25,\n",
      "                          81,                   21,                  110,\n",
      "                          63,                   69,                  400,\n",
      "                           9,                   11,                   20,\n",
      "                         129,                  315,                  317,\n",
      "                         122,                  202,                    1,\n",
      "                           3,                    2,                    2,\n",
      "                          32,                    4,                    3,\n",
      "                           0,                    1,                   44,\n",
      "                          43,                  169,                    5,\n",
      "                         101,                  242,                  221,\n",
      "                           0,                    0,                    0,\n",
      "                          27,                    0,                   28,\n",
      "                          81,                  204,                   20,\n",
      "                           1,                    2,                    3,\n",
      "                           0,                   11,                    0,\n",
      "                           0,                    2,                    0,\n",
      "                          49,                   78,                  411,\n",
      "                         490,                  109,                   80,\n",
      "                          68,                   67,                  240,\n",
      "                         548,                 1247,                  255,\n",
      "                        2007,                  128,                  163,\n",
      "                         171,                  371,                  183,\n",
      "                         368,                  383,                  354,\n",
      "                         501,                  178,                  698,\n",
      "                         480,                  298,                  304,\n",
      "                         838,                  591,                  542,\n",
      "                         319,                  107,                  720,\n",
      "                         239,                  383,                  223,\n",
      "                         315,                 1183,                  133,\n",
      "                        3078,                  234,                  795,\n",
      "                         180,                  188,                 1591,\n",
      "                         198,                 4197,                 1591,\n",
      "                         709,                 2308,                 3551,\n",
      "                        2429,                 3298,                  887,\n",
      "                           0])\n"
     ]
    }
   ],
   "source": [
    "pos_weight = neg / inst_sum\n",
    "print(pos_weight.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    0,     0,     0,     0, 25758,   723,   300,   342,   709,   195,\n",
      "          862,   157,  1264, 11379,   730,  6129,  5857,  4921,  6224,   236,\n",
      "          285,   229,   289,  1565,   277,   728,   577,   122,  1843,  1734,\n",
      "          562,  2065,   415,   713,   652,   115,  4529,  3615,  2193,   355,\n",
      "          146,   145,   374,   227, 16963, 11370, 14240, 14010,  1379,  8758,\n",
      "         9241, 26186, 19252,  1011,  1029,   271,  6613,   450,   190,   208,\n",
      "        36920, 30527, 25915,  1596, 34516,  1553,   563,   225,  2156, 16172,\n",
      "        13834, 10948, 28672,  3767, 25725, 34334, 13628, 38641,   908,   579,\n",
      "          112,    94,   417,   567,   669,   675,   191,    84,    37,   180,\n",
      "           23,   358,   281,   268,   124,   251,   125,   120,   130,    92,\n",
      "          258,    66,    96,   154,   151,    55,    78,    85,   144,   427,\n",
      "           64,   192,   120,   206,   146,    39,   343,    15,   196,    58,\n",
      "          254,   244,    29,   232,    11,    29,    65,    20,    13,    19,\n",
      "           14,    52, 30432])\n"
     ]
    }
   ],
   "source": [
    "print(inst_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
