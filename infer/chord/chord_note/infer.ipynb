{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chord_Note_LSTM(\n",
       "  (chord_embedding): Embedding(150, 256, padding_idx=0)\n",
       "  (note_embedding): Embedding(832, 256, padding_idx=0)\n",
       "  (lstm): LSTM(512, 256, num_layers=3, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=150, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from transformers import T5Config, T5ForConditionalGeneration, AdamW\n",
    "from transformers import BertConfig, BertModel, BertLMHeadModel, BartConfig, BartModel\n",
    "\n",
    "path_prefix = '/workspace/out/chord_note'\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "class Chord_Note_LSTM(nn.Module):\n",
    "    def __init__(self, chord_size=150, note_size=832, chord_dim=512, note_dim=512, num_note=2, hidden_dim=512, num_layers=5):\n",
    "        super(Chord_Note_LSTM, self).__init__()\n",
    "        self.chord_embedding = nn.Embedding(chord_size, chord_dim, padding_idx=0)\n",
    "        self.note_embedding = nn.Embedding(note_size, note_dim, padding_idx=0)\n",
    "        self.num_note = num_note\n",
    "        self.lstm = nn.LSTM(chord_dim+(note_dim*num_note), hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, chord_size)\n",
    "        \n",
    "        self.epsilon = 1e-9\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=0.01, eps=1e-9)\n",
    "        self.scheduler = optim.lr_scheduler.LambdaLR(optimizer=self.optimizer, lr_lambda=lambda epoch: 0.95 ** epoch)\n",
    "        # self.scheduler = CosineAnnealingWarmRestarts(self.optimizer, T_0=5, T_mult=2, eta_min=0.001)\n",
    "\n",
    "    def forward(self, note, chord):\n",
    "        chord_embed = self.chord_embedding(chord)\n",
    "        note_embed = self.note_embedding(note)\n",
    "        \n",
    "        bsz, seq_length, depth, embed_dim = note_embed.shape\n",
    "        # assert depth == self.num_note\n",
    "        note_embed = note_embed.mean(dim=2)\n",
    "        \n",
    "        input_embed = torch.cat([chord_embed, note_embed], dim=2)\n",
    "        \n",
    "        output, (hidden, cell) = self.lstm(input_embed)\n",
    "        \n",
    "        logits = self.fc(output)\n",
    "        \n",
    "        return logits\n",
    "    \n",
    "    def infer(self, note, chord, length=2048):\n",
    "        if len(chord.shape) == 1:\n",
    "            chord = chord.unsqueeze(0)\n",
    "        if len(chord.shape) > 2:\n",
    "            raise Exception\n",
    "        \n",
    "        \n",
    "        if length > 2048:\n",
    "            print(\"Max Length is 2048. Change Length Auto to 2048\")\n",
    "            length = 2048\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for step in range(length):\n",
    "                chord_length = chord.shape[1]\n",
    "                \n",
    "                output = self.forward(note[:,:chord_length], chord)\n",
    "                output = torch.argmax(output, dim=2)\n",
    "                predict = output[:,-1].unsqueeze(1)\n",
    "                \n",
    "                output_ids = torch.cat((chord, predict), dim=-1)\n",
    "\n",
    "                chord = output_ids\n",
    "                \n",
    "                # if torch.all(predict.eq(0)):\n",
    "                #     break\n",
    "                if chord_length == note.shape[1]:\n",
    "                    print(\"MAX NOTE LENGTH\")\n",
    "                    break\n",
    "                \n",
    "                if predict[0,0] == 1:\n",
    "                    print(\"EOS DETECT!!\")\n",
    "                    break\n",
    "                \n",
    "                if output_ids.shape[1] > 2048:\n",
    "                    break\n",
    "                \n",
    "                if step % 50 == 0:\n",
    "                    print(f'{step} Generate...')\n",
    "\n",
    "        return output_ids\n",
    "    \n",
    "    \n",
    "model = Chord_Note_LSTM(chord_dim=256, note_dim=256, num_note=1, hidden_dim=256, num_layers=3)\n",
    "model.load_state_dict(torch.load(path_prefix + '/LSTM_4Note_Avg/model_72_0.3374_0.2445.pt', map_location=device))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "base_model = 'LSTM'\n",
    "n_notes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading original txt file...: 1198it [00:00, 4090.55it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "reading original txt file...: 46188it [00:10, 4244.87it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SymDataset(Dataset):\n",
    "    def __init__(self, data, base_model, n_notes):\n",
    "        super().__init__()\n",
    "        self.data = data\n",
    "        self.base_model = base_model\n",
    "        self.n_notes = n_notes\n",
    "        \n",
    "        chord_vocab_path = '/workspace/data/vocabs/chord.json'\n",
    "        with open(chord_vocab_path, 'r') as file:\n",
    "            self.chord_vocab = json.load(file)\n",
    "            \n",
    "        note_vocab_path = '/workspace/data/vocabs/note.json'\n",
    "        with open(note_vocab_path, 'r') as file:\n",
    "            self.note_vocab = json.load(file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text_seq = self.data[idx]\n",
    "        \n",
    "        if isinstance(text_seq, str):\n",
    "            toks = text_seq.split()\n",
    "        l_toks = len(toks)\n",
    "        ratio = 4\n",
    "        \n",
    "        measure_list = []\n",
    "        chord_list = []\n",
    "        note_list = []\n",
    "        \n",
    "        note_in_measure = []\n",
    "        for idx in range(0, l_toks, ratio):\n",
    "            # 4개 단위로 txt token 도는중\n",
    "            t1, t2, t3, t4 = toks[idx : idx + 4]\n",
    "            \n",
    "            if t1[0] == 'm' or t1[0] == 'M':\n",
    "                measure_list.append(t1)\n",
    "                # 이전 마디 정보 update\n",
    "                note_list.append(note_in_measure[-self.n_notes:])\n",
    "                note_in_measure = []\n",
    "            \n",
    "            if t1[0] == 'h' or t1[0] == 'H':\n",
    "                chord_list.append(t1)\n",
    "                \n",
    "            if t1 in self.note_vocab:\n",
    "                if t1 not in note_in_measure:\n",
    "                    note_in_measure.append(t1)\n",
    "        # 마무리 note 정보 update\n",
    "        # 최근 8개\n",
    "        note_list.append(note_in_measure[-self.n_notes:])\n",
    "        # 처음 M에서 들어간거 삭제\n",
    "        note_list = note_list[1:767][:]\n",
    "        \n",
    "        # 코드는 Grouping 단위로 해주는 get_chord\n",
    "        target_chord_seq = self.get_chord_seq(chord_list)\n",
    "        # 문자에서 숫자로\n",
    "        target_chord_tensor = [self.chord_vocab[chd] for chd in target_chord_seq]\n",
    "        target_chord_tensor = [2] + target_chord_tensor[:766] + [1]\n",
    "        target_chord_tensor = torch.tensor(target_chord_tensor)\n",
    "        \n",
    "        # Note 문자에서 숫자로\n",
    "        target_note_tensor = self.get_note_seq(note_list)\n",
    "        target_note_tensor = [[2]*self.n_notes] + target_note_tensor + [[1]*self.n_notes]\n",
    "        target_note_tensor = torch.tensor(target_note_tensor)\n",
    "\n",
    "        assert target_note_tensor.shape[0] == target_chord_tensor.shape[0]\n",
    "\n",
    "        return target_chord_tensor, target_note_tensor\n",
    "    \n",
    "    \n",
    "    def get_chord_seq(self, chord_list):\n",
    "        group_list = []\n",
    "        for idx in range(0, len(chord_list)):\n",
    "            group_list.append(chord_list[idx])\n",
    "            \n",
    "        return group_list\n",
    "    \n",
    "    def get_note_seq(self, note_list):\n",
    "        target_note_tensor = []\n",
    "        for n_list in note_list:\n",
    "            n_tensor = [0]*self.n_notes\n",
    "            if len(n_list) > self.n_notes:\n",
    "                raise Exception\n",
    "            \n",
    "            for idx, n in enumerate(n_list):\n",
    "                vocab = self.note_vocab[n]\n",
    "                n_tensor[idx] = vocab\n",
    "            target_note_tensor.append(n_tensor)\n",
    "        return target_note_tensor\n",
    "    \n",
    "def create_dataloaders(batch_size, base_model, n_notes):\n",
    "    raw_data_path = '../../../workspace/data/corpus/raw_corpus_bpe.txt'\n",
    "    raw_data = []\n",
    "    with open(raw_data_path, 'r') as f:\n",
    "        for line in tqdm(f, desc=\"reading original txt file...\"):\n",
    "            raw_data.append(line.strip())\n",
    "            \n",
    "    train, val_test = train_test_split(raw_data, test_size=0.1, random_state=5)\n",
    "    val, test = train_test_split(val_test, test_size=0.2, random_state=5)\n",
    "    \n",
    "    train_dataset = SymDataset(train, base_model, n_notes)\n",
    "    val_dataset = SymDataset(val, base_model, n_notes)\n",
    "    test_dataset = SymDataset(test, base_model, n_notes)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=collate_batch)\n",
    "\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def collate_batch(batch):\n",
    "    chords, notes = zip(*batch)\n",
    "    # padding_value = <eos>\n",
    "    chord_padded = pad_sequence(chords, padding_value=0, batch_first=True)\n",
    "    note_padded = pad_sequence(notes, padding_value=0, batch_first=True)\n",
    "    return chord_padded[:,:-1], chord_padded[:,1:], note_padded[:,:-1,:]\n",
    "    \n",
    "train_loader, val_loader, test_loader = create_dataloaders(batch_size, base_model, n_notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET SAMPLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IN sample\n",
      "tensor([[  2,  15,  44,  92,  61,  15,  44,  92,  61,  16,  92,  93,  61,  16,\n",
      "          92,  93,  62,  15,  21,  92,  61,  15,  21,  92,  61,  16,  92,  92,\n",
      "          65,  16,  92,  92,  61, 117,  92,  92,  61,  61,  21,  92,  16,  15,\n",
      "          92,  92,  61,  15,  92,  92,  61,  15,  34,  92,  16,  15,  92,  93,\n",
      "          61,  16,  37,  92,  84, 117,  37,  92, 116, 117,   7,  92,  61,  16,\n",
      "          37,   6,  59,  15,  93,  93,  61,  15,  93,  93,  61,  16,  92,  92,\n",
      "          65,  16,  92,  92,  61,  16,  92,  92,  61,  61, 118,  92,  61,  16,\n",
      "          36,  92,  61,  16, 122,  92,  61, 100,  34,  92,  61,  16,  36,   7,\n",
      "          61,  15,  92,  92,  61,  15,  92,  92,  61,  15,  92,  92,  61,  15,\n",
      "          92,  92,  61,  16,  92,  92,  61,  15,  40,  92,  61,  16,  92,  92,\n",
      "          61,  15,  93,  92,  61,  16,  36,   6,  16,  16,  36,  93,  62,  16,\n",
      "          36,  37,  62]], device='cuda:0')\n",
      "torch.Size([1, 157])\n",
      "Train OUT sample\n",
      "tensor([[ 15,  44,  92,  61,  15,  44,  92,  61,  16,  92,  93,  61,  16,  92,\n",
      "          93,  62,  15,  21,  92,  61,  15,  21,  92,  61,  16,  92,  92,  65,\n",
      "          16,  92,  92,  61, 117,  92,  92,  61,  61,  21,  92,  16,  15,  92,\n",
      "          92,  61,  15,  92,  92,  61,  15,  34,  92,  16,  15,  92,  93,  61,\n",
      "          16,  37,  92,  84, 117,  37,  92, 116, 117,   7,  92,  61,  16,  37,\n",
      "           6,  59,  15,  93,  93,  61,  15,  93,  93,  61,  16,  92,  92,  65,\n",
      "          16,  92,  92,  61,  16,  92,  92,  61,  61, 118,  92,  61,  16,  36,\n",
      "          92,  61,  16, 122,  92,  61, 100,  34,  92,  61,  16,  36,   7,  61,\n",
      "          15,  92,  92,  61,  15,  92,  92,  61,  15,  92,  92,  61,  15,  92,\n",
      "          92,  61,  16,  92,  92,  61,  15,  40,  92,  61,  16,  92,  92,  61,\n",
      "          15,  93,  92,  61,  16,  36,   6,  16,  16,  36,  93,  62,  16,  36,\n",
      "          37,  62,   1]], device='cuda:0')\n",
      "torch.Size([1, 157])\n",
      "Train Note sample\n",
      "tensor([[[  2,   2,   2,   2],\n",
      "         [ 43,  53,  65,  57],\n",
      "         [ 55, 455,  43,  65],\n",
      "         [ 60,  57,  64,  55],\n",
      "         [401,  45,  57,  64],\n",
      "         [ 65,  57,  60,  59],\n",
      "         [455,  43,  65,  59],\n",
      "         [ 57,  64,  55,  59],\n",
      "         [ 76,  59,  69,  72],\n",
      "         [ 69,  71,  67,  72],\n",
      "         [ 43,  74,  67,  71],\n",
      "         [ 69,  65,  71,  64],\n",
      "         [ 57,  76,  69,  72],\n",
      "         [ 69,  71,  67,  72],\n",
      "         [ 43,  74,  67,  71],\n",
      "         [ 67,  69,  65,  71],\n",
      "         [ 64,  62,  67,  65],\n",
      "         [ 69,  67,  57,  60],\n",
      "         [ 65,  71,  67,  60],\n",
      "         [ 71,  69,  67,  55],\n",
      "         [578,  71,  67,  60],\n",
      "         [ 72,  71,  57,  60],\n",
      "         [641,  67,  71,  60],\n",
      "         [ 69,  67,  76,  55],\n",
      "         [ 64, 641,  67,  60],\n",
      "         [ 74,  64,  65,  62],\n",
      "         [455,  43,  74,  62],\n",
      "         [ 72,  76,  62,  64],\n",
      "         [ 69,  76,  59,  64],\n",
      "         [ 74,  64,  65,  62],\n",
      "         [455,  43,  72,  60],\n",
      "         [ 74,  72,  64,  62],\n",
      "         [ 77,  59,  55,  48],\n",
      "         [ 74,  72,  76,  57],\n",
      "         [ 76,  60,  59,  52],\n",
      "         [ 69,  74,  55,  52],\n",
      "         [ 45,  60,  59,  55],\n",
      "         [ 43,  71,  72,  57],\n",
      "         [ 69,  59,  52,  65],\n",
      "         [ 65,  69,  55,  52],\n",
      "         [ 45,  65,  69,  64],\n",
      "         [ 81,  79,  69,  67],\n",
      "         [ 77,  62,  64,  65],\n",
      "         [ 76,  67,  65,  64],\n",
      "         [ 71,  72,  59,  60],\n",
      "         [ 81,  79,  69,  67],\n",
      "         [ 67,  62,  64,  65],\n",
      "         [ 76,  67,  65,  64],\n",
      "         [ 71,  72,  59,  60],\n",
      "         [ 83,  69,  67,  71],\n",
      "         [455,  36,  83,  71],\n",
      "         [ 79,  77,  67,  65],\n",
      "         [ 77,  76,  65,  64],\n",
      "         [ 77,  74,  65,  62],\n",
      "         [ 72,  74,  60,  62],\n",
      "         [ 76,  72,  59,  64],\n",
      "         [ 57,  50,  55,  59],\n",
      "         [ 43,  72,  60,  65],\n",
      "         [ 77,  69,  57,  60],\n",
      "         [ 79,  45,  69,  57],\n",
      "         [ 50,  52,  53,  55],\n",
      "         [ 72,  62,  65,  64],\n",
      "         [ 67,  55,  57,  53],\n",
      "         [ 45,  69,  60,  57],\n",
      "         [ 50,  52,  53,  55],\n",
      "         [ 72,  62,  64,  65],\n",
      "         [ 43,  76,  64,  67],\n",
      "         [ 71,  60,  59,  62],\n",
      "         [ 72,  76,  69,  57],\n",
      "         [ 77,  67,  59,  55],\n",
      "         [ 55,  53,  59,  57],\n",
      "         [ 52,  57,  53,  55],\n",
      "         [ 39, 171,  45,  33],\n",
      "         [ 43,  72,  71,  76],\n",
      "         [732,  72,  71,  76],\n",
      "         [ 79,  72,  71,  76],\n",
      "         [ 64,  72,  71,  76],\n",
      "         [ 65,  72,  71,  76],\n",
      "         [732,  72,  71,  76],\n",
      "         [ 79,  72,  71,  76],\n",
      "         [ 64,  76,  72,  71],\n",
      "         [ 74,  64,  65,  62],\n",
      "         [455,  43,  74,  62],\n",
      "         [ 72,  76,  62,  64],\n",
      "         [ 69,  76,  59,  64],\n",
      "         [ 74,  64,  65,  62],\n",
      "         [455,  43,  72,  60],\n",
      "         [ 74,  72,  64,  62],\n",
      "         [ 71,  67,  65,  64],\n",
      "         [ 69,  65,  67,  64],\n",
      "         [ 71,  64,  69,  65],\n",
      "         [ 77,  67,  64,  65],\n",
      "         [ 72,  71,  69,  67],\n",
      "         [ 65,  62,  69,  67],\n",
      "         [ 71,  67,  64,  65],\n",
      "         [ 72,  64,  62,  67],\n",
      "         [ 72,  60,  64,  48],\n",
      "         [ 67,  41,  43,  65],\n",
      "         [ 64,  65,  43,  67],\n",
      "         [ 72,  69,  60,  57],\n",
      "         [ 59,  60,  45,  64],\n",
      "         [ 41,  43,  65,  53],\n",
      "         [ 65,  60,  43,  67],\n",
      "         [ 72,  69,  60,  57],\n",
      "         [ 59,  60,  45,  64],\n",
      "         [ 71,  41,  43,  65],\n",
      "         [ 71,  43,  67,  65],\n",
      "         [ 72,  69,  64,  57],\n",
      "         [ 57,  76,  64,  69],\n",
      "         [ 62,  72,  76,  53],\n",
      "         [ 62,  60,  71,  55],\n",
      "         [ 59,  60,  67,  55],\n",
      "         [ 65,  69,  52,  64],\n",
      "         [ 36,  41,  43,  53],\n",
      "         [ 39,  55, 455,  36],\n",
      "         [ 48,  45,  60,  57],\n",
      "         [ 39, 401,  36,  57],\n",
      "         [ 36,  41,  43,  53],\n",
      "         [ 39,  55, 455,  36],\n",
      "         [ 48,  45,  60,  57],\n",
      "         [ 39, 401,  36,  57],\n",
      "         [ 36,  41,  43,  53],\n",
      "         [ 39,  55, 455,  36],\n",
      "         [ 52, 646, 695,  55],\n",
      "         [ 79,  84,  83,  81],\n",
      "         [ 48,  50,  65,  67],\n",
      "         [ 84,  83,  50,  67],\n",
      "         [ 55,  52,  72,  69],\n",
      "         [ 83,  81,  48,  69],\n",
      "         [ 65,  79,  52,  71],\n",
      "         [ 84,  83,  53,  71],\n",
      "         [ 76,  52,  47,  67],\n",
      "         [ 83,  81,  48,  64],\n",
      "         [ 67,  48,  50,  65],\n",
      "         [ 64,  65,  50,  67],\n",
      "         [ 55,  52,  72,  69],\n",
      "         [ 59,  52,  48,  64],\n",
      "         [ 69,  67,  52,  71],\n",
      "         [ 64,  60,  53,  71],\n",
      "         [ 59,  67,  52,  47],\n",
      "         [ 81,  59,  48,  64],\n",
      "         [ 71,  48,  50,  65],\n",
      "         [ 84,  71,  50,  67],\n",
      "         [ 55,  52,  72,  69],\n",
      "         [ 83,  64,  48,  69],\n",
      "         [ 48,  69,  72,  64],\n",
      "         [ 60,  47,  67,  71],\n",
      "         [ 64,  60,  43,  67],\n",
      "         [ 74,  41,  60,  65],\n",
      "         [ 72,  45,  57,  60],\n",
      "         [ 65,  71,  55,  59],\n",
      "         [ 62,  43,  55,  59],\n",
      "         [ 72,  43,  55,  60],\n",
      "         [ 69,  72,  57,  60],\n",
      "         [ 67,  71,  55,  59],\n",
      "         [ 67,  71,  55,  59],\n",
      "         [ 67,  72,  55,  60]]], device='cuda:0')\n",
      "torch.Size([1, 157, 4])\n"
     ]
    }
   ],
   "source": [
    "for i, o, note in train_loader:\n",
    "    train_note = note.to(device)\n",
    "    train_in_sample = i.to(device)\n",
    "    train_out_sample =  o.to(device)\n",
    "    break\n",
    "\n",
    "for i, o, note in val_loader:\n",
    "    val_note = note.to(device)\n",
    "    val_in_sample = i.to(device)\n",
    "    val_out_sample =  o.to(device)\n",
    "    break\n",
    "\n",
    "for i, o, note in test_loader:\n",
    "    test_note = note.to(device)\n",
    "    test_in_sample = i.to(device)\n",
    "    test_out_sample =  o.to(device)\n",
    "    break\n",
    "\n",
    "print(\"Train IN sample\")\n",
    "print(train_in_sample)\n",
    "print(train_in_sample.shape)\n",
    "print(\"Train OUT sample\")\n",
    "print(train_out_sample)\n",
    "print(train_out_sample.shape)\n",
    "print(\"Train Note sample\")\n",
    "print(train_note)\n",
    "print(train_note.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt Chord\n",
      "tensor([[  2,   5,  52,  82,  29,   5,  52, 133,  29,  48,  52,  82,  29,   5,\n",
      "          52,  74,  29,  50,  71, 128, 128,  48,  50,  81,  48,   5,   4,  25,\n",
      "          80,  49]], device='cuda:0')\n",
      "Answer Chord\n",
      "tensor([[  5,  52,  82,  29,   5,  52, 133,  29,  48,  52,  82,  29,   5,  52,\n",
      "          74,  29,  50,  71, 128, 128,  48,  50,  81,  48,   5,   4,  25,  80,\n",
      "          49,  71,  70,  92,  70, 127,  51,  51,  70, 128,  51,  51,  33,  32,\n",
      "           5,  52, 129,  29,  51,  52, 129,  82,  48,  69,  25,  82,  51,  69,\n",
      "          25, 129,   5,  52, 129,  29,  51,  52, 129,  80,  26, 128,  26, 128,\n",
      "          26, 128, 103, 128,  47,  47, 126, 126,  16, 117,  62,  62,  82, 102,\n",
      "         132, 126,  82, 102, 132, 125, 127,   7,   7,  62,  80,   7,  62,  62,\n",
      "          80,   7,   7,  62,  80,   7,  93,  62,   7,  37, 133,  48,  52,  82,\n",
      "         115,   5,  52, 107,  29,  51,  52,   5,  29,  51,  52, 133, 115,   5,\n",
      "          50,   1]], device='cuda:0')\n",
      "torch.Size([1, 128])\n",
      "Prompt Note\n",
      "tensor([[[  2,   2,   2,   2],\n",
      "         [ 32,  48, 740, 799],\n",
      "         [509,  37, 740, 714],\n",
      "         [549,  34, 720, 785],\n",
      "         [ 38, 672, 751, 740],\n",
      "         [ 32,  48, 740, 799],\n",
      "         [542,  37, 740, 714],\n",
      "         [ 32,  34, 720, 785],\n",
      "         [ 37,  38, 672, 751],\n",
      "         [ 78,  82, 740, 799],\n",
      "         [ 83,  80, 740, 714],\n",
      "         [ 74,  73, 720, 785],\n",
      "         [ 73, 672, 751, 740],\n",
      "         [ 78,  82, 740, 799],\n",
      "         [ 83,  80, 740, 714],\n",
      "         [ 73,  72, 720, 785],\n",
      "         [ 75,  77, 672, 751],\n",
      "         [ 46,  34,  36,  37],\n",
      "         [ 41,  42,  40,  37],\n",
      "         [ 82,  73,  85,  75],\n",
      "         [706,  79, 738,  82],\n",
      "         [661, 710, 740, 799],\n",
      "         [677, 640, 740, 714],\n",
      "         [687, 664, 720, 785],\n",
      "         [ 75, 672, 751, 740],\n",
      "         [677, 661, 740, 799],\n",
      "         [687,  80, 740, 714],\n",
      "         [649, 661, 720, 785],\n",
      "         [687, 710, 672, 751],\n",
      "         [ 32,  33,  35,  69],\n",
      "         [ 34,  35,  36,  71],\n",
      "         [ 75,  76,  77,  78],\n",
      "         [ 91,  41, 695, 777],\n",
      "         [ 74,  73,  75,  59],\n",
      "         [ 38, 684,  59,  83],\n",
      "         [ 73, 722,  59,  83],\n",
      "         [740, 761,  59,  83],\n",
      "         [ 73,  75,  59,  83],\n",
      "         [ 37, 684,  59,  83],\n",
      "         [ 68, 641,  59,  83],\n",
      "         [641, 687,  59,  83],\n",
      "         [ 92, 787,  59,  83],\n",
      "         [695, 653, 804,  59],\n",
      "         [799,  75,  78,  77],\n",
      "         [ 41, 740, 714,  80],\n",
      "         [720, 785,  76,  73],\n",
      "         [672, 751,  75,  73],\n",
      "         [799,  75,  78,  77],\n",
      "         [ 42, 740, 714,  80],\n",
      "         [720, 785,  76,  73],\n",
      "         [ 35, 672, 751,  75],\n",
      "         [ 32,  80,  78,  82],\n",
      "         [ 41,  82,  83,  80],\n",
      "         [701, 699, 687, 664],\n",
      "         [687, 710,  75,  73],\n",
      "         [ 49,  80,  78,  82],\n",
      "         [ 42,  82,  83,  80],\n",
      "         [701, 699, 687, 664],\n",
      "         [ 56, 549,  73, 507],\n",
      "         [799,  75,  78,  77],\n",
      "         [ 41, 740, 714,  80],\n",
      "         [720, 785,  76,  73],\n",
      "         [672, 751,  75,  73],\n",
      "         [799,  75,  78,  77],\n",
      "         [ 42, 740, 714,  80],\n",
      "         [720, 785,  76,  73],\n",
      "         [614,  66,  35,  75],\n",
      "         [470, 614,  63, 498],\n",
      "         [614,  64, 553, 527],\n",
      "         [614,  63, 498,  78],\n",
      "         [ 51,  54, 302, 321],\n",
      "         [498,  82,  83,  70],\n",
      "         [ 77,  82, 624,  73],\n",
      "         [ 73,  75,  78, 586],\n",
      "         [581, 321, 341, 302],\n",
      "         [ 91,  93,  94, 586],\n",
      "         [670, 693, 716, 665],\n",
      "         [672, 713,  84, 760],\n",
      "         [294, 304, 341, 322],\n",
      "         [534, 565, 483, 501],\n",
      "         [294, 311, 341, 322],\n",
      "         [ 46,  34,  60,  64],\n",
      "         [341, 369, 415, 387],\n",
      "         [ 70,  68,  71,  72],\n",
      "         [ 72, 369, 400, 432],\n",
      "         [ 73, 670,  77,  78],\n",
      "         [369, 400, 450, 418],\n",
      "         [ 70,  68,  71,  72],\n",
      "         [ 72, 369, 400, 432],\n",
      "         [ 78,  79,  80,  81],\n",
      "         [650,  96,  44, 730],\n",
      "         [672, 695,  75,  59],\n",
      "         [ 79, 695,  83,  59],\n",
      "         [ 80, 732,  59,  83],\n",
      "         [ 47,  35, 751, 769],\n",
      "         [ 77,  78,  59,  83],\n",
      "         [ 79, 696,  59,  83],\n",
      "         [ 80, 653,  59,  83],\n",
      "         [653, 699,  59,  83],\n",
      "         [ 76,  77,  78,  59],\n",
      "         [ 79, 695,  59,  83],\n",
      "         [ 80, 732,  59,  83],\n",
      "         [ 47,  35, 751, 769],\n",
      "         [ 77,  78,  59,  83],\n",
      "         [ 79, 696,  59,  83],\n",
      "         [ 80, 653,  59,  83],\n",
      "         [653, 699,  59,  83],\n",
      "         [ 88,  93, 795,  59],\n",
      "         [708, 809,  59,  83],\n",
      "         [  0,   0,   0,   0],\n",
      "         [ 78,  82, 740, 799],\n",
      "         [ 83,  80, 740, 714],\n",
      "         [ 74,  73, 720, 785],\n",
      "         [ 73, 672, 751, 740],\n",
      "         [ 78,  82, 740, 799],\n",
      "         [ 83,  80, 740, 714],\n",
      "         [ 75,  73, 720, 785],\n",
      "         [ 75,  77, 672, 751],\n",
      "         [ 37,  38, 740, 799],\n",
      "         [ 35,  36, 740, 714],\n",
      "         [ 41,  38, 720, 785],\n",
      "         [ 32, 672, 751, 740],\n",
      "         [ 37,  38, 740, 799],\n",
      "         [ 38,  40, 740, 714],\n",
      "         [549,  52, 720, 785],\n",
      "         [597, 483, 672, 751],\n",
      "         [516, 630, 740, 799],\n",
      "         [516, 630,  74, 502]]], device='cuda:0')\n",
      "torch.Size([1, 128, 4])\n"
     ]
    }
   ],
   "source": [
    "print(\"Prompt Chord\")\n",
    "print(val_in_sample[:,:30])\n",
    "print(\"Answer Chord\")\n",
    "print(val_out_sample)\n",
    "print(val_out_sample.shape)\n",
    "print(\"Prompt Note\")\n",
    "print(val_note)\n",
    "print(val_note.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Generate...\n",
      "50 Generate...\n",
      "EOS DETECT!!\n",
      "tensor([[ 2, 15, 44, 92, 61, 15, 44, 92, 61, 16, 92, 93, 61, 16, 92, 93, 62, 15,\n",
      "         21, 92, 61, 15, 21, 92, 61, 16, 92, 92, 65, 16, 92, 92, 61, 15, 92, 92,\n",
      "         61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15,\n",
      "         92, 92, 61, 15, 92, 92, 59, 15, 92, 92, 43, 21, 92, 92, 61, 15, 92, 92,\n",
      "         61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15,\n",
      "         92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92,\n",
      "         61, 15, 92, 92, 61, 15, 92, 92, 61, 15, 92, 92,  1]], device='cuda:0')\n",
      "torch.Size([1, 121])\n"
     ]
    }
   ],
   "source": [
    "sample_output = model.infer(train_note, train_in_sample[:,:30])\n",
    "print(sample_output)\n",
    "print(sample_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
